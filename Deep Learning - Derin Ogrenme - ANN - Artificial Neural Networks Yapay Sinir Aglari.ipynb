{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f4086bf1",
   "metadata": {},
   "source": [
    "1- Derin Ogrenmede Feature Engineering@ e gerek yok\n",
    "2- Tensorflow Kullaniyoruz. Keras - API Kullaniyour\n",
    "3- Tensor - COk boyutlu Matrix Flow akis Google tarafindan gelistirildi. Rakip - Facebook Pytorch\n",
    "4- GPU (Ekran Kartlari ile hesap yapmak daha hizli)\n",
    "5- Derin Ogrenme insan beyninin ogrenme seklini kopyalar, insan beyni nasil ogrenirse yapay sinir aglari da oyle ogrenir\n",
    "6- Nöronlar arasında gidip gelme işlemine epoch denir\n",
    "7- Her nörondan diğerine bir ağırlık aktarılık (katsayı) aktarılır\n",
    "8- Aktarma işlemine Ativasyon fonksiyonu karar verir: ReLU, Softmax, Sigmoid\n",
    "9- Resimler çok büyük olduğu için parça - parça işlenir buna batch-size denir\n",
    "10- Resimler üzerinde çalılıyorsanız CNN kullanılır.\n",
    "11- Resim, Text(yazı), Video üretme işlemler LSTM ile yapılır. (Long-Short Time Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9565c8",
   "metadata": {},
   "source": [
    "### Deep Learning ile Makine Öğrenmesi 1-Classification 2- Regression 3 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8791d7",
   "metadata": {},
   "source": [
    "1 - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bceaf07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\kubra\\anaconda\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kubra\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kubra\\anaconda\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: keras in c:\\users\\kubra\\anaconda\\lib\\site-packages (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2684e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f01b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "260b0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e14e6571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52373c3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8769a534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dfe5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c3f68ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[[\"Outcome\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae313f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:8]\n",
    "y=df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b7175c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e3fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(120,activation='relu'))\n",
    "model.add(Dense(60,activation='relu'))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(2,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "402b7e5f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7930\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.7930\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.7982\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4348 - accuracy: 0.8021\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.7956\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8060\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8008\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4171 - accuracy: 0.7930\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4335 - accuracy: 0.7891\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.7930\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.7956\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.7943\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.7904\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.7982\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4168 - accuracy: 0.8034\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4152 - accuracy: 0.7943\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.7878\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.7930\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7826\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.7930\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.7982\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4213 - accuracy: 0.7930\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.7917\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.7943\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.7995\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.7891\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8008\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7982\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7943\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7943\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.7956\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7956\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7930\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7878\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8047\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8034\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7930\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7865\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7995\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8021\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7917\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7943\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.7930\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7943\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.7891\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.7904\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.7956\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7812\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.8047\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8008\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.7839\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.8034\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8021\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7956\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7969\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.7943\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.7956\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7891\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.7956\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.8021\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.7982\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7930\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8099\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4106 - accuracy: 0.7982\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8060\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.7839\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.7917\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.7995\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.7878\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4134 - accuracy: 0.7982\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.7917\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8008\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.7995\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.7956\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.7969\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.7943\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7773\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8060\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.7930\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.7969\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7904\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.7930\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7982\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7943\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8008\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7826\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7956\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7904\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8047\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8008\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7943\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8034\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8047\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7904\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.7930\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.7956\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8099\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7786\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7891\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.7943\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.7917\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7943\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.7982\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.7930\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4045 - accuracy: 0.7982\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7982\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.7930\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.7982\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8086\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8034\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8008\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.7904\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.7878\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8060\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.7995\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7930\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7995\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.7904\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.7943\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.7956\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7969\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.7995\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.7956\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7865\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.7969\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8008\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7982\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7917\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7852\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8008\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.7956\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4145 - accuracy: 0.7878\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4041 - accuracy: 0.8008\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8060\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8008\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.7995\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.7956\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8008\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.7969\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.7943\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.7943\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7930\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.7878\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.7943\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.7969\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8021\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8034\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8034\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8034\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20208cdc460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=1500,batch_size=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cd56528",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 52        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 237\n",
      "Trainable params: 237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0299f358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8099\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "863155cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4064585864543915"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35367b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8098958134651184"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18fd4223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09f23836",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.3729 - accuracy: 0.8257 - val_loss: 0.5987 - val_accuracy: 0.7662\n",
      "Epoch 2/19\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3614 - accuracy: 0.8111 - val_loss: 0.5888 - val_accuracy: 0.7727\n",
      "Epoch 3/19\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.3883 - accuracy: 0.8143 - val_loss: 0.5871 - val_accuracy: 0.7727\n",
      "Epoch 4/19\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3686 - accuracy: 0.8274 - val_loss: 0.5642 - val_accuracy: 0.7532\n",
      "Epoch 5/19\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3799 - accuracy: 0.8062 - val_loss: 0.5870 - val_accuracy: 0.7662\n",
      "Epoch 6/19\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3689 - accuracy: 0.8143 - val_loss: 0.5681 - val_accuracy: 0.7662\n",
      "Epoch 7/19\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8160 - val_loss: 0.5744 - val_accuracy: 0.7403\n",
      "Epoch 8/19\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3587 - accuracy: 0.8225 - val_loss: 0.6151 - val_accuracy: 0.7662\n",
      "Epoch 9/19\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3542 - accuracy: 0.8322 - val_loss: 0.5793 - val_accuracy: 0.7597\n",
      "Epoch 10/19\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3645 - accuracy: 0.8257 - val_loss: 0.5953 - val_accuracy: 0.7662\n",
      "Epoch 11/19\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3655 - accuracy: 0.8208 - val_loss: 0.5780 - val_accuracy: 0.7727\n",
      "Epoch 12/19\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.3749 - accuracy: 0.8127 - val_loss: 0.6623 - val_accuracy: 0.7468\n",
      "Epoch 13/19\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.3656 - accuracy: 0.8257 - val_loss: 0.5996 - val_accuracy: 0.7727\n",
      "Epoch 14/19\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3666 - accuracy: 0.8192 - val_loss: 0.6577 - val_accuracy: 0.7403\n",
      "Epoch 15/19\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.3757 - accuracy: 0.8225 - val_loss: 0.6549 - val_accuracy: 0.7338\n",
      "Epoch 16/19\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3636 - accuracy: 0.8257 - val_loss: 0.5843 - val_accuracy: 0.7338\n",
      "Epoch 17/19\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.3590 - accuracy: 0.8274 - val_loss: 0.5797 - val_accuracy: 0.7532\n",
      "Epoch 18/19\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.3608 - accuracy: 0.8225 - val_loss: 0.6197 - val_accuracy: 0.7792\n",
      "Epoch 19/19\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3637 - accuracy: 0.8355 - val_loss: 0.5999 - val_accuracy: 0.7532\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y,epochs=19,validation_split=0.20,batch_size=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1a3d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eae31c83",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2020f7dff10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"],label=\"Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"],label=\"ValAccuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a56c4",
   "metadata": {},
   "source": [
    "2-Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33cd1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2320c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"kc_house.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a270cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"kcdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9850b7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>view</th>\n",
       "      <th>basement</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>age</th>\n",
       "      <th>renovated</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>price</th>\n",
       "      <th>zipcode_98002</th>\n",
       "      <th>zipcode_98003</th>\n",
       "      <th>zipcode_98004</th>\n",
       "      <th>zipcode_98005</th>\n",
       "      <th>zipcode_98006</th>\n",
       "      <th>zipcode_98007</th>\n",
       "      <th>zipcode_98008</th>\n",
       "      <th>zipcode_98010</th>\n",
       "      <th>zipcode_98011</th>\n",
       "      <th>zipcode_98014</th>\n",
       "      <th>zipcode_98019</th>\n",
       "      <th>zipcode_98022</th>\n",
       "      <th>zipcode_98023</th>\n",
       "      <th>zipcode_98024</th>\n",
       "      <th>zipcode_98027</th>\n",
       "      <th>zipcode_98028</th>\n",
       "      <th>zipcode_98029</th>\n",
       "      <th>zipcode_98030</th>\n",
       "      <th>zipcode_98031</th>\n",
       "      <th>zipcode_98032</th>\n",
       "      <th>zipcode_98033</th>\n",
       "      <th>zipcode_98034</th>\n",
       "      <th>zipcode_98038</th>\n",
       "      <th>zipcode_98039</th>\n",
       "      <th>zipcode_98040</th>\n",
       "      <th>zipcode_98042</th>\n",
       "      <th>zipcode_98045</th>\n",
       "      <th>zipcode_98052</th>\n",
       "      <th>zipcode_98053</th>\n",
       "      <th>zipcode_98055</th>\n",
       "      <th>zipcode_98056</th>\n",
       "      <th>zipcode_98058</th>\n",
       "      <th>zipcode_98059</th>\n",
       "      <th>zipcode_98065</th>\n",
       "      <th>zipcode_98070</th>\n",
       "      <th>zipcode_98072</th>\n",
       "      <th>zipcode_98074</th>\n",
       "      <th>zipcode_98075</th>\n",
       "      <th>zipcode_98077</th>\n",
       "      <th>zipcode_98092</th>\n",
       "      <th>zipcode_98102</th>\n",
       "      <th>zipcode_98103</th>\n",
       "      <th>zipcode_98105</th>\n",
       "      <th>zipcode_98106</th>\n",
       "      <th>zipcode_98107</th>\n",
       "      <th>zipcode_98108</th>\n",
       "      <th>zipcode_98109</th>\n",
       "      <th>zipcode_98112</th>\n",
       "      <th>zipcode_98115</th>\n",
       "      <th>zipcode_98116</th>\n",
       "      <th>zipcode_98117</th>\n",
       "      <th>zipcode_98118</th>\n",
       "      <th>zipcode_98119</th>\n",
       "      <th>zipcode_98122</th>\n",
       "      <th>zipcode_98125</th>\n",
       "      <th>zipcode_98126</th>\n",
       "      <th>zipcode_98133</th>\n",
       "      <th>zipcode_98136</th>\n",
       "      <th>zipcode_98144</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1180</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2170</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>770</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1050</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1680</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  grade  view  basement  waterfront  \\\n",
       "0         9     1.0000         1180      7     0         0           0   \n",
       "1         9     5.0625         2570      7     0         1           0   \n",
       "2         4     1.0000          770      6     0         0           0   \n",
       "3        16     9.0000         1960      7     0         1           0   \n",
       "4         9     4.0000         1680      8     0         0           0   \n",
       "\n",
       "   floors  age  renovated  condition  sqft_above     price  zipcode_98002  \\\n",
       "0     1.0   65          0          3        1180  221900.0              0   \n",
       "1     2.0   69          1          3        2170  538000.0              0   \n",
       "2     1.0   87          0          3         770  180000.0              0   \n",
       "3     1.0   55          0          5        1050  604000.0              0   \n",
       "4     1.0   33          0          3        1680  510000.0              0   \n",
       "\n",
       "   zipcode_98003  zipcode_98004  zipcode_98005  zipcode_98006  zipcode_98007  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98008  zipcode_98010  zipcode_98011  zipcode_98014  zipcode_98019  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98022  zipcode_98023  zipcode_98024  zipcode_98027  zipcode_98028  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              1   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98029  zipcode_98030  zipcode_98031  zipcode_98032  zipcode_98033  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98034  zipcode_98038  zipcode_98039  zipcode_98040  zipcode_98042  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98045  zipcode_98052  zipcode_98053  zipcode_98055  zipcode_98056  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98058  zipcode_98059  zipcode_98065  zipcode_98070  zipcode_98072  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98074  zipcode_98075  zipcode_98077  zipcode_98092  zipcode_98102  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              1              0              0              0              0   \n",
       "\n",
       "   zipcode_98103  zipcode_98105  zipcode_98106  zipcode_98107  zipcode_98108  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98109  zipcode_98112  zipcode_98115  zipcode_98116  zipcode_98117  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98118  zipcode_98119  zipcode_98122  zipcode_98125  zipcode_98126  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              1              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98133  zipcode_98136  zipcode_98144  zipcode_98146  zipcode_98148  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              1              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98155  zipcode_98166  zipcode_98168  zipcode_98177  zipcode_98178  \\\n",
       "0              0              0              0              0              1   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98188  zipcode_98198  zipcode_98199  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfdd9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"price\",axis=1)\n",
    "y=df[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec23ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6db13b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc1939ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02010855",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7cc5a481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "119/119 [==============================] - 4s 13ms/step - loss: 269884604416.0000 - val_loss: 235764285440.0000\n",
      "Epoch 2/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 88140808192.0000 - val_loss: 34042607616.0000\n",
      "Epoch 3/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 33536409600.0000 - val_loss: 33824464896.0000\n",
      "Epoch 4/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 33255481344.0000 - val_loss: 33412759552.0000\n",
      "Epoch 5/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 32921368576.0000 - val_loss: 33103071232.0000\n",
      "Epoch 6/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 32589105152.0000 - val_loss: 32792440832.0000\n",
      "Epoch 7/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 32231165952.0000 - val_loss: 32475383808.0000\n",
      "Epoch 8/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 31906117632.0000 - val_loss: 32180750336.0000\n",
      "Epoch 9/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 31622301696.0000 - val_loss: 31871946752.0000\n",
      "Epoch 10/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 31249999872.0000 - val_loss: 31494457344.0000\n",
      "Epoch 11/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 30894043136.0000 - val_loss: 31186081792.0000\n",
      "Epoch 12/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 30561992704.0000 - val_loss: 30877779968.0000\n",
      "Epoch 13/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 30258544640.0000 - val_loss: 30568273920.0000\n",
      "Epoch 14/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 29917253632.0000 - val_loss: 30233042944.0000\n",
      "Epoch 15/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 29651357696.0000 - val_loss: 29997471744.0000\n",
      "Epoch 16/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 29328795648.0000 - val_loss: 29686919168.0000\n",
      "Epoch 17/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 29052180480.0000 - val_loss: 29465858048.0000\n",
      "Epoch 18/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 28863303680.0000 - val_loss: 29262858240.0000\n",
      "Epoch 19/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 28729804800.0000 - val_loss: 29134202880.0000\n",
      "Epoch 20/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 28514510848.0000 - val_loss: 29003587584.0000\n",
      "Epoch 21/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 28379346944.0000 - val_loss: 28858019840.0000\n",
      "Epoch 22/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 28283955200.0000 - val_loss: 28777234432.0000\n",
      "Epoch 23/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 28222758912.0000 - val_loss: 28707854336.0000\n",
      "Epoch 24/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 28152184832.0000 - val_loss: 28724875264.0000\n",
      "Epoch 25/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 28102559744.0000 - val_loss: 28591661056.0000\n",
      "Epoch 26/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 28013920256.0000 - val_loss: 28550699008.0000\n",
      "Epoch 27/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27946618880.0000 - val_loss: 28609787904.0000\n",
      "Epoch 28/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 27960481792.0000 - val_loss: 28477276160.0000\n",
      "Epoch 29/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 27915413504.0000 - val_loss: 28567486464.0000\n",
      "Epoch 30/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27834064896.0000 - val_loss: 28384729088.0000\n",
      "Epoch 31/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27775447040.0000 - val_loss: 28347136000.0000\n",
      "Epoch 32/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27745603584.0000 - val_loss: 28312991744.0000\n",
      "Epoch 33/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 27687270400.0000 - val_loss: 28354693120.0000\n",
      "Epoch 34/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27648874496.0000 - val_loss: 28241389568.0000\n",
      "Epoch 35/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27658334208.0000 - val_loss: 28231436288.0000\n",
      "Epoch 36/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27584499712.0000 - val_loss: 28192851968.0000\n",
      "Epoch 37/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27528599552.0000 - val_loss: 28152287232.0000\n",
      "Epoch 38/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 27490930688.0000 - val_loss: 28096714752.0000\n",
      "Epoch 39/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27549892608.0000 - val_loss: 28305520640.0000\n",
      "Epoch 40/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 27429423104.0000 - val_loss: 28047736832.0000\n",
      "Epoch 41/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 27393427456.0000 - val_loss: 28065128448.0000\n",
      "Epoch 42/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27357650944.0000 - val_loss: 27942418432.0000\n",
      "Epoch 43/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 27302946816.0000 - val_loss: 27903883264.0000\n",
      "Epoch 44/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27268993024.0000 - val_loss: 27848765440.0000\n",
      "Epoch 45/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27193872384.0000 - val_loss: 27986987008.0000\n",
      "Epoch 46/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27212996608.0000 - val_loss: 27767736320.0000\n",
      "Epoch 47/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 27059488768.0000 - val_loss: 27788865536.0000\n",
      "Epoch 48/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27037075456.0000 - val_loss: 27642216448.0000\n",
      "Epoch 49/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 26987323392.0000 - val_loss: 27727284224.0000\n",
      "Epoch 50/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 26980763648.0000 - val_loss: 27523313664.0000\n",
      "Epoch 51/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 26843420672.0000 - val_loss: 27477932032.0000\n",
      "Epoch 52/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 26760599552.0000 - val_loss: 27414654976.0000\n",
      "Epoch 53/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 26738149376.0000 - val_loss: 27507752960.0000\n",
      "Epoch 54/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 26651955200.0000 - val_loss: 27379185664.0000\n",
      "Epoch 55/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 26535096320.0000 - val_loss: 27212691456.0000\n",
      "Epoch 56/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 26541324288.0000 - val_loss: 27200212992.0000\n",
      "Epoch 57/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 26402891776.0000 - val_loss: 26972915712.0000\n",
      "Epoch 58/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 26309836800.0000 - val_loss: 26914410496.0000\n",
      "Epoch 59/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 26223093760.0000 - val_loss: 26800271360.0000\n",
      "Epoch 60/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 26098350080.0000 - val_loss: 26652674048.0000\n",
      "Epoch 61/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 25932795904.0000 - val_loss: 26506973184.0000\n",
      "Epoch 62/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 25784969216.0000 - val_loss: 26668963840.0000\n",
      "Epoch 63/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 25626599424.0000 - val_loss: 26207670272.0000\n",
      "Epoch 64/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 25478952960.0000 - val_loss: 26076194816.0000\n",
      "Epoch 65/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 25282820096.0000 - val_loss: 25895362560.0000\n",
      "Epoch 66/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 25110265856.0000 - val_loss: 25626279936.0000\n",
      "Epoch 67/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 24832509952.0000 - val_loss: 25333108736.0000\n",
      "Epoch 68/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 24581513216.0000 - val_loss: 25073037312.0000\n",
      "Epoch 69/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 24266291200.0000 - val_loss: 24731297792.0000\n",
      "Epoch 70/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 23930423296.0000 - val_loss: 24408031232.0000\n",
      "Epoch 71/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 23537641472.0000 - val_loss: 24019800064.0000\n",
      "Epoch 72/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 23116638208.0000 - val_loss: 23573811200.0000\n",
      "Epoch 73/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 22648025088.0000 - val_loss: 23158147072.0000\n",
      "Epoch 74/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 22248361984.0000 - val_loss: 22508935168.0000\n",
      "Epoch 75/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 21616254976.0000 - val_loss: 22058799104.0000\n",
      "Epoch 76/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 21143896064.0000 - val_loss: 21509058560.0000\n",
      "Epoch 77/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 20633262080.0000 - val_loss: 20996286464.0000\n",
      "Epoch 78/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 20082898944.0000 - val_loss: 20613984256.0000\n",
      "Epoch 79/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 19822716928.0000 - val_loss: 20243621888.0000\n",
      "Epoch 80/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 19343314944.0000 - val_loss: 20241534976.0000\n",
      "Epoch 81/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 19235862528.0000 - val_loss: 19967938560.0000\n",
      "Epoch 82/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 19026241536.0000 - val_loss: 20720871424.0000\n",
      "Epoch 83/1500\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 18776524800.0000 - val_loss: 19297990656.0000\n",
      "Epoch 84/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 18336688128.0000 - val_loss: 19302746112.0000\n",
      "Epoch 85/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 18199023616.0000 - val_loss: 18905022464.0000\n",
      "Epoch 86/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 18023583744.0000 - val_loss: 18785810432.0000\n",
      "Epoch 87/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 17745375232.0000 - val_loss: 18867476480.0000\n",
      "Epoch 88/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 17661831168.0000 - val_loss: 18562566144.0000\n",
      "Epoch 89/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 17418545152.0000 - val_loss: 18211125248.0000\n",
      "Epoch 90/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 17193771008.0000 - val_loss: 17933121536.0000\n",
      "Epoch 91/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 17025549312.0000 - val_loss: 17742561280.0000\n",
      "Epoch 92/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 16737276928.0000 - val_loss: 17567229952.0000\n",
      "Epoch 93/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 16621812736.0000 - val_loss: 17467627520.0000\n",
      "Epoch 94/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 16416189440.0000 - val_loss: 17193637888.0000\n",
      "Epoch 95/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 16157903872.0000 - val_loss: 17543524352.0000\n",
      "Epoch 96/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 16124649472.0000 - val_loss: 17131139072.0000\n",
      "Epoch 97/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 15842527232.0000 - val_loss: 16866836480.0000\n",
      "Epoch 98/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 15870105600.0000 - val_loss: 17913520128.0000\n",
      "Epoch 99/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 15615708160.0000 - val_loss: 16311374848.0000\n",
      "Epoch 100/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 15353525248.0000 - val_loss: 16240141312.0000\n",
      "Epoch 101/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 15110119424.0000 - val_loss: 16113103872.0000\n",
      "Epoch 102/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 14931058688.0000 - val_loss: 15954436096.0000\n",
      "Epoch 103/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 14798856192.0000 - val_loss: 16015904768.0000\n",
      "Epoch 104/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 14638435328.0000 - val_loss: 15571885056.0000\n",
      "Epoch 105/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 14345819136.0000 - val_loss: 15233233920.0000\n",
      "Epoch 106/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 14250880000.0000 - val_loss: 15068982272.0000\n",
      "Epoch 107/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 14104853504.0000 - val_loss: 14911647744.0000\n",
      "Epoch 108/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 13868606464.0000 - val_loss: 14833181696.0000\n",
      "Epoch 109/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 13863552000.0000 - val_loss: 14860221440.0000\n",
      "Epoch 110/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 13580112896.0000 - val_loss: 14541532160.0000\n",
      "Epoch 111/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 13573300224.0000 - val_loss: 14517268480.0000\n",
      "Epoch 112/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 13506746368.0000 - val_loss: 14333790208.0000\n",
      "Epoch 113/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 13266805760.0000 - val_loss: 14038985728.0000\n",
      "Epoch 114/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 13173917696.0000 - val_loss: 13924496384.0000\n",
      "Epoch 115/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 13023239168.0000 - val_loss: 14336220160.0000\n",
      "Epoch 116/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 12956246016.0000 - val_loss: 13788493824.0000\n",
      "Epoch 117/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 12911188992.0000 - val_loss: 13609005056.0000\n",
      "Epoch 118/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 12713966592.0000 - val_loss: 14631450624.0000\n",
      "Epoch 119/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 12625945600.0000 - val_loss: 13392428032.0000\n",
      "Epoch 120/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 12621020160.0000 - val_loss: 13272580096.0000\n",
      "Epoch 121/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 12309584896.0000 - val_loss: 13379933184.0000\n",
      "Epoch 122/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 12317191168.0000 - val_loss: 13110962176.0000\n",
      "Epoch 123/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 12139036672.0000 - val_loss: 13044148224.0000\n",
      "Epoch 124/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 12066140160.0000 - val_loss: 13065545728.0000\n",
      "Epoch 125/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 12098476032.0000 - val_loss: 13213528064.0000\n",
      "Epoch 126/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 11879766016.0000 - val_loss: 12756716544.0000\n",
      "Epoch 127/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 11929147392.0000 - val_loss: 12807229440.0000\n",
      "Epoch 128/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 11758011392.0000 - val_loss: 12652968960.0000\n",
      "Epoch 129/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 11879792640.0000 - val_loss: 12636032000.0000\n",
      "Epoch 130/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 11762882560.0000 - val_loss: 12566409216.0000\n",
      "Epoch 131/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 11576786944.0000 - val_loss: 12623343616.0000\n",
      "Epoch 132/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 11742089216.0000 - val_loss: 12450790400.0000\n",
      "Epoch 133/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 8ms/step - loss: 11583835136.0000 - val_loss: 12303058944.0000\n",
      "Epoch 134/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 11442259968.0000 - val_loss: 12323110912.0000\n",
      "Epoch 135/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 11413506048.0000 - val_loss: 12192405504.0000\n",
      "Epoch 136/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 11309937664.0000 - val_loss: 12735428608.0000\n",
      "Epoch 137/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 11266493440.0000 - val_loss: 12205130752.0000\n",
      "Epoch 138/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 11157172224.0000 - val_loss: 12035368960.0000\n",
      "Epoch 139/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 11269762048.0000 - val_loss: 11968607232.0000\n",
      "Epoch 140/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 11100000256.0000 - val_loss: 11974899712.0000\n",
      "Epoch 141/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 11068290048.0000 - val_loss: 12118416384.0000\n",
      "Epoch 142/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 11135689728.0000 - val_loss: 12467984384.0000\n",
      "Epoch 143/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 11186231296.0000 - val_loss: 11812451328.0000\n",
      "Epoch 144/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10964920320.0000 - val_loss: 11835396096.0000\n",
      "Epoch 145/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10936725504.0000 - val_loss: 12070326272.0000\n",
      "Epoch 146/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10951602176.0000 - val_loss: 12058230784.0000\n",
      "Epoch 147/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10869735424.0000 - val_loss: 11645822976.0000\n",
      "Epoch 148/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10800571392.0000 - val_loss: 11705199616.0000\n",
      "Epoch 149/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10981217280.0000 - val_loss: 11875013632.0000\n",
      "Epoch 150/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10819670016.0000 - val_loss: 11538001920.0000\n",
      "Epoch 151/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10802985984.0000 - val_loss: 11515331584.0000\n",
      "Epoch 152/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10864627712.0000 - val_loss: 11460990976.0000\n",
      "Epoch 153/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10648682496.0000 - val_loss: 11746222080.0000\n",
      "Epoch 154/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10776279040.0000 - val_loss: 11360191488.0000\n",
      "Epoch 155/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10718267392.0000 - val_loss: 12391051264.0000\n",
      "Epoch 156/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10765931520.0000 - val_loss: 11763518464.0000\n",
      "Epoch 157/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10515515392.0000 - val_loss: 11291901952.0000\n",
      "Epoch 158/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10517511168.0000 - val_loss: 11323295744.0000\n",
      "Epoch 159/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10510470144.0000 - val_loss: 11678301184.0000\n",
      "Epoch 160/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10465154048.0000 - val_loss: 11389958144.0000\n",
      "Epoch 161/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10747813888.0000 - val_loss: 11460298752.0000\n",
      "Epoch 162/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10452103168.0000 - val_loss: 11215867904.0000\n",
      "Epoch 163/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10386088960.0000 - val_loss: 11110787072.0000\n",
      "Epoch 164/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10394423296.0000 - val_loss: 11115974656.0000\n",
      "Epoch 165/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10479403008.0000 - val_loss: 11041268736.0000\n",
      "Epoch 166/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10337855488.0000 - val_loss: 11360517120.0000\n",
      "Epoch 167/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10339390464.0000 - val_loss: 11091468288.0000\n",
      "Epoch 168/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10334133248.0000 - val_loss: 11083097088.0000\n",
      "Epoch 169/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10253212672.0000 - val_loss: 10933470208.0000\n",
      "Epoch 170/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10366720000.0000 - val_loss: 10927657984.0000\n",
      "Epoch 171/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10227886080.0000 - val_loss: 11142146048.0000\n",
      "Epoch 172/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10160393216.0000 - val_loss: 11237581824.0000\n",
      "Epoch 173/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 10113251328.0000 - val_loss: 11496152064.0000\n",
      "Epoch 174/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10236145664.0000 - val_loss: 10956473344.0000\n",
      "Epoch 175/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10027131904.0000 - val_loss: 10777963520.0000\n",
      "Epoch 176/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 10220910592.0000 - val_loss: 10770720768.0000\n",
      "Epoch 177/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10002451456.0000 - val_loss: 10735940608.0000\n",
      "Epoch 178/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10089111552.0000 - val_loss: 10725578752.0000\n",
      "Epoch 179/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 10015456256.0000 - val_loss: 10707593216.0000\n",
      "Epoch 180/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9951250432.0000 - val_loss: 10658948096.0000\n",
      "Epoch 181/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 10013606912.0000 - val_loss: 10958434304.0000\n",
      "Epoch 182/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10032214016.0000 - val_loss: 11544097792.0000\n",
      "Epoch 183/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9896822784.0000 - val_loss: 10673918976.0000\n",
      "Epoch 184/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9912907776.0000 - val_loss: 10738198528.0000\n",
      "Epoch 185/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9985490944.0000 - val_loss: 10625231872.0000\n",
      "Epoch 186/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9892201472.0000 - val_loss: 10771169280.0000\n",
      "Epoch 187/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9967251456.0000 - val_loss: 11173026816.0000\n",
      "Epoch 188/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 10046910464.0000 - val_loss: 10482959360.0000\n",
      "Epoch 189/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9898385408.0000 - val_loss: 10676304896.0000\n",
      "Epoch 190/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9932706816.0000 - val_loss: 10465940480.0000\n",
      "Epoch 191/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9822389248.0000 - val_loss: 10837601280.0000\n",
      "Epoch 192/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9959646208.0000 - val_loss: 10473611264.0000\n",
      "Epoch 193/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9843931136.0000 - val_loss: 10497991680.0000\n",
      "Epoch 194/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9679700992.0000 - val_loss: 10617022464.0000\n",
      "Epoch 195/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9695972352.0000 - val_loss: 10356613120.0000\n",
      "Epoch 196/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9667714048.0000 - val_loss: 10360689664.0000\n",
      "Epoch 197/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9795078144.0000 - val_loss: 11056318464.0000\n",
      "Epoch 198/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9665390592.0000 - val_loss: 11046264832.0000\n",
      "Epoch 199/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9636755456.0000 - val_loss: 10292958208.0000\n",
      "Epoch 200/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9609897984.0000 - val_loss: 10555684864.0000\n",
      "Epoch 201/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9771016192.0000 - val_loss: 10287558656.0000\n",
      "Epoch 202/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9673073664.0000 - val_loss: 10473708544.0000\n",
      "Epoch 203/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9554959360.0000 - val_loss: 10208027648.0000\n",
      "Epoch 204/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9682024448.0000 - val_loss: 10168869888.0000\n",
      "Epoch 205/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 9623301120.0000 - val_loss: 10171138048.0000\n",
      "Epoch 206/1500\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 9596890112.0000 - val_loss: 10200367104.0000\n",
      "Epoch 207/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 9574400000.0000 - val_loss: 10316099584.0000\n",
      "Epoch 208/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 9492393984.0000 - val_loss: 10128457728.0000\n",
      "Epoch 209/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 9409222656.0000 - val_loss: 10552795136.0000\n",
      "Epoch 210/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 9502520320.0000 - val_loss: 10411005952.0000\n",
      "Epoch 211/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 9517308928.0000 - val_loss: 10382830592.0000\n",
      "Epoch 212/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9497815040.0000 - val_loss: 10104987648.0000\n",
      "Epoch 213/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 9405679616.0000 - val_loss: 11346259968.0000\n",
      "Epoch 214/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 9488061440.0000 - val_loss: 10298438656.0000\n",
      "Epoch 215/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 9469219840.0000 - val_loss: 10011656192.0000\n",
      "Epoch 216/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 9419852800.0000 - val_loss: 10106525696.0000\n",
      "Epoch 217/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9457629184.0000 - val_loss: 10058519552.0000\n",
      "Epoch 218/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 9352183808.0000 - val_loss: 9947335680.0000\n",
      "Epoch 219/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9383094272.0000 - val_loss: 9953239040.0000\n",
      "Epoch 220/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 9355248640.0000 - val_loss: 9919958016.0000\n",
      "Epoch 221/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 9302440960.0000 - val_loss: 9928724480.0000\n",
      "Epoch 222/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 9325360128.0000 - val_loss: 9918560256.0000\n",
      "Epoch 223/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9343064064.0000 - val_loss: 9987543040.0000\n",
      "Epoch 224/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9298575360.0000 - val_loss: 9874749440.0000\n",
      "Epoch 225/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9305091072.0000 - val_loss: 9933009920.0000\n",
      "Epoch 226/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 9317390336.0000 - val_loss: 9828793344.0000\n",
      "Epoch 227/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9169886208.0000 - val_loss: 10296437760.0000\n",
      "Epoch 228/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 9438352384.0000 - val_loss: 10492848128.0000\n",
      "Epoch 229/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9615694848.0000 - val_loss: 9941635072.0000\n",
      "Epoch 230/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9202538496.0000 - val_loss: 9832604672.0000\n",
      "Epoch 231/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9210667008.0000 - val_loss: 9822707712.0000\n",
      "Epoch 232/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 9218260992.0000 - val_loss: 9763212288.0000\n",
      "Epoch 233/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9152056320.0000 - val_loss: 9856662528.0000\n",
      "Epoch 234/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9352899584.0000 - val_loss: 9966680064.0000\n",
      "Epoch 235/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9187040256.0000 - val_loss: 9731609600.0000\n",
      "Epoch 236/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9270967296.0000 - val_loss: 9873336320.0000\n",
      "Epoch 237/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9269098496.0000 - val_loss: 9731485696.0000\n",
      "Epoch 238/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9118399488.0000 - val_loss: 9711986688.0000\n",
      "Epoch 239/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9201278976.0000 - val_loss: 9702683648.0000\n",
      "Epoch 240/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9267362816.0000 - val_loss: 9734666240.0000\n",
      "Epoch 241/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9053329408.0000 - val_loss: 9838065664.0000\n",
      "Epoch 242/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9094103040.0000 - val_loss: 9871303680.0000\n",
      "Epoch 243/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9045129216.0000 - val_loss: 9771942912.0000\n",
      "Epoch 244/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9137495040.0000 - val_loss: 9651596288.0000\n",
      "Epoch 245/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9038086144.0000 - val_loss: 9745062912.0000\n",
      "Epoch 246/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9106558976.0000 - val_loss: 9631790080.0000\n",
      "Epoch 247/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9029533696.0000 - val_loss: 9895590912.0000\n",
      "Epoch 248/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9038947328.0000 - val_loss: 9732758528.0000\n",
      "Epoch 249/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9054945280.0000 - val_loss: 9619539968.0000\n",
      "Epoch 250/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9018684416.0000 - val_loss: 9655591936.0000\n",
      "Epoch 251/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9053892608.0000 - val_loss: 9562966016.0000\n",
      "Epoch 252/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9017491456.0000 - val_loss: 9659305984.0000\n",
      "Epoch 253/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9092213760.0000 - val_loss: 9716853760.0000\n",
      "Epoch 254/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8923086848.0000 - val_loss: 9569388544.0000\n",
      "Epoch 255/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8999398400.0000 - val_loss: 9905510400.0000\n",
      "Epoch 256/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9135101952.0000 - val_loss: 9699186688.0000\n",
      "Epoch 257/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9038483456.0000 - val_loss: 10002902016.0000\n",
      "Epoch 258/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8972589056.0000 - val_loss: 9680310272.0000\n",
      "Epoch 259/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9036166144.0000 - val_loss: 9510980608.0000\n",
      "Epoch 260/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9024176128.0000 - val_loss: 9550465024.0000\n",
      "Epoch 261/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8900814848.0000 - val_loss: 9925275648.0000\n",
      "Epoch 262/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9117475840.0000 - val_loss: 9596772352.0000\n",
      "Epoch 263/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8925707264.0000 - val_loss: 9674471424.0000\n",
      "Epoch 264/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9089398784.0000 - val_loss: 9816809472.0000\n",
      "Epoch 265/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8924351488.0000 - val_loss: 9517587456.0000\n",
      "Epoch 266/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 6ms/step - loss: 8940191744.0000 - val_loss: 9979335680.0000\n",
      "Epoch 267/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8890228736.0000 - val_loss: 10311905280.0000\n",
      "Epoch 268/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8864242688.0000 - val_loss: 9643386880.0000\n",
      "Epoch 269/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8918895616.0000 - val_loss: 9431117824.0000\n",
      "Epoch 270/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8935633920.0000 - val_loss: 9384314880.0000\n",
      "Epoch 271/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9041438720.0000 - val_loss: 9537511424.0000\n",
      "Epoch 272/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8883821568.0000 - val_loss: 9962044416.0000\n",
      "Epoch 273/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8934664192.0000 - val_loss: 9407492096.0000\n",
      "Epoch 274/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9009179648.0000 - val_loss: 9589372928.0000\n",
      "Epoch 275/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8821426176.0000 - val_loss: 9391380480.0000\n",
      "Epoch 276/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8791643136.0000 - val_loss: 9373095936.0000\n",
      "Epoch 277/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8776864768.0000 - val_loss: 9344288768.0000\n",
      "Epoch 278/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8944992256.0000 - val_loss: 9502535680.0000\n",
      "Epoch 279/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8753926144.0000 - val_loss: 9361750016.0000\n",
      "Epoch 280/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8922289152.0000 - val_loss: 9341428736.0000\n",
      "Epoch 281/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 9101068288.0000 - val_loss: 9747107840.0000\n",
      "Epoch 282/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8963032064.0000 - val_loss: 9370999808.0000\n",
      "Epoch 283/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8721733632.0000 - val_loss: 9536122880.0000\n",
      "Epoch 284/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8782658560.0000 - val_loss: 9871774720.0000\n",
      "Epoch 285/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8879978496.0000 - val_loss: 9287373824.0000\n",
      "Epoch 286/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8925317120.0000 - val_loss: 9438940160.0000\n",
      "Epoch 287/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8812273664.0000 - val_loss: 9332452352.0000\n",
      "Epoch 288/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8810836992.0000 - val_loss: 10725335040.0000\n",
      "Epoch 289/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8835258368.0000 - val_loss: 9546803200.0000\n",
      "Epoch 290/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8840782848.0000 - val_loss: 9866109952.0000\n",
      "Epoch 291/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8683505664.0000 - val_loss: 9784611840.0000\n",
      "Epoch 292/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8719751168.0000 - val_loss: 9249393664.0000\n",
      "Epoch 293/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8994004992.0000 - val_loss: 9242975232.0000\n",
      "Epoch 294/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8724663296.0000 - val_loss: 9257577472.0000\n",
      "Epoch 295/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8733724672.0000 - val_loss: 9319826432.0000\n",
      "Epoch 296/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8680844288.0000 - val_loss: 9248872448.0000\n",
      "Epoch 297/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8759256064.0000 - val_loss: 9294167040.0000\n",
      "Epoch 298/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8608611328.0000 - val_loss: 9302996992.0000\n",
      "Epoch 299/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8630027264.0000 - val_loss: 9525006336.0000\n",
      "Epoch 300/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8710259712.0000 - val_loss: 9310718976.0000\n",
      "Epoch 301/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8720274432.0000 - val_loss: 10860713984.0000\n",
      "Epoch 302/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8726915072.0000 - val_loss: 9529697280.0000\n",
      "Epoch 303/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8679287808.0000 - val_loss: 9548693504.0000\n",
      "Epoch 304/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8682140672.0000 - val_loss: 9234233344.0000\n",
      "Epoch 305/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8654803968.0000 - val_loss: 9205741568.0000\n",
      "Epoch 306/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8781721600.0000 - val_loss: 9248830464.0000\n",
      "Epoch 307/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8598322176.0000 - val_loss: 9276590080.0000\n",
      "Epoch 308/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9178180608.0000 - val_loss: 9160980480.0000\n",
      "Epoch 309/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8623194112.0000 - val_loss: 9271645184.0000\n",
      "Epoch 310/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8612629504.0000 - val_loss: 9155424256.0000\n",
      "Epoch 311/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8666803200.0000 - val_loss: 9204048896.0000\n",
      "Epoch 312/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8603852800.0000 - val_loss: 9360061440.0000\n",
      "Epoch 313/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8552156160.0000 - val_loss: 9162788864.0000\n",
      "Epoch 314/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8535579136.0000 - val_loss: 9128689664.0000\n",
      "Epoch 315/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8559037952.0000 - val_loss: 10450313216.0000\n",
      "Epoch 316/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8738848768.0000 - val_loss: 9167286272.0000\n",
      "Epoch 317/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8598863872.0000 - val_loss: 9339523072.0000\n",
      "Epoch 318/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9066301440.0000 - val_loss: 9208815616.0000\n",
      "Epoch 319/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8612767744.0000 - val_loss: 9144670208.0000\n",
      "Epoch 320/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8510721024.0000 - val_loss: 9147389952.0000\n",
      "Epoch 321/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8577676800.0000 - val_loss: 9115572224.0000\n",
      "Epoch 322/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8528485376.0000 - val_loss: 9545566208.0000\n",
      "Epoch 323/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8700855296.0000 - val_loss: 10078162944.0000\n",
      "Epoch 324/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8553949696.0000 - val_loss: 9449981952.0000\n",
      "Epoch 325/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8548289024.0000 - val_loss: 10110640128.0000\n",
      "Epoch 326/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8600851456.0000 - val_loss: 9136541696.0000\n",
      "Epoch 327/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8543503360.0000 - val_loss: 9104177152.0000\n",
      "Epoch 328/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8968756224.0000 - val_loss: 9354656768.0000\n",
      "Epoch 329/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8520508928.0000 - val_loss: 9073181696.0000\n",
      "Epoch 330/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8509561856.0000 - val_loss: 9347581952.0000\n",
      "Epoch 331/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8566645760.0000 - val_loss: 9169313792.0000\n",
      "Epoch 332/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8664862720.0000 - val_loss: 9132779520.0000\n",
      "Epoch 333/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8602763264.0000 - val_loss: 9292810240.0000\n",
      "Epoch 334/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8537241600.0000 - val_loss: 9056958464.0000\n",
      "Epoch 335/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8606280704.0000 - val_loss: 9168004096.0000\n",
      "Epoch 336/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8642336768.0000 - val_loss: 9106582528.0000\n",
      "Epoch 337/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8503327232.0000 - val_loss: 9543435264.0000\n",
      "Epoch 338/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8640235520.0000 - val_loss: 9099575296.0000\n",
      "Epoch 339/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8563936768.0000 - val_loss: 10365595648.0000\n",
      "Epoch 340/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8613410816.0000 - val_loss: 9002309632.0000\n",
      "Epoch 341/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8510180864.0000 - val_loss: 9139798016.0000\n",
      "Epoch 342/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8432656384.0000 - val_loss: 9224927232.0000\n",
      "Epoch 343/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8660469760.0000 - val_loss: 9528337408.0000\n",
      "Epoch 344/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8636199936.0000 - val_loss: 9088023552.0000\n",
      "Epoch 345/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8514092032.0000 - val_loss: 9095555072.0000\n",
      "Epoch 346/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8548642304.0000 - val_loss: 9012881408.0000\n",
      "Epoch 347/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8415450112.0000 - val_loss: 9044661248.0000\n",
      "Epoch 348/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8571260416.0000 - val_loss: 9116095488.0000\n",
      "Epoch 349/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8535319040.0000 - val_loss: 9201000448.0000\n",
      "Epoch 350/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8462902272.0000 - val_loss: 8986436608.0000\n",
      "Epoch 351/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8545789952.0000 - val_loss: 9063718912.0000\n",
      "Epoch 352/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8458589696.0000 - val_loss: 9057218560.0000\n",
      "Epoch 353/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8416870400.0000 - val_loss: 9109408768.0000\n",
      "Epoch 354/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8462918656.0000 - val_loss: 9568310272.0000\n",
      "Epoch 355/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8446243328.0000 - val_loss: 9026450432.0000\n",
      "Epoch 356/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8368123904.0000 - val_loss: 8993115136.0000\n",
      "Epoch 357/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8725933056.0000 - val_loss: 8965354496.0000\n",
      "Epoch 358/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8641845248.0000 - val_loss: 8958217216.0000\n",
      "Epoch 359/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8524254720.0000 - val_loss: 9356492800.0000\n",
      "Epoch 360/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8593728512.0000 - val_loss: 8964090880.0000\n",
      "Epoch 361/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8456867840.0000 - val_loss: 9175274496.0000\n",
      "Epoch 362/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8537941504.0000 - val_loss: 8954718208.0000\n",
      "Epoch 363/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8519881728.0000 - val_loss: 8993250304.0000\n",
      "Epoch 364/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8396234752.0000 - val_loss: 9105774592.0000\n",
      "Epoch 365/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8800913408.0000 - val_loss: 9023355904.0000\n",
      "Epoch 366/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8417007616.0000 - val_loss: 9145530368.0000\n",
      "Epoch 367/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8475464192.0000 - val_loss: 10089842688.0000\n",
      "Epoch 368/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8469999104.0000 - val_loss: 8995646464.0000\n",
      "Epoch 369/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8450359808.0000 - val_loss: 8928206848.0000\n",
      "Epoch 370/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8480840192.0000 - val_loss: 8943669248.0000\n",
      "Epoch 371/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8533506048.0000 - val_loss: 8997980160.0000\n",
      "Epoch 372/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8561484288.0000 - val_loss: 9566460928.0000\n",
      "Epoch 373/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8467432448.0000 - val_loss: 9360583680.0000\n",
      "Epoch 374/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8546284544.0000 - val_loss: 9204618240.0000\n",
      "Epoch 375/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8452939264.0000 - val_loss: 8972512256.0000\n",
      "Epoch 376/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8330585088.0000 - val_loss: 8917737472.0000\n",
      "Epoch 377/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8355003392.0000 - val_loss: 8908780544.0000\n",
      "Epoch 378/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8386827776.0000 - val_loss: 9339123712.0000\n",
      "Epoch 379/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8471730688.0000 - val_loss: 9089646592.0000\n",
      "Epoch 380/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8370885120.0000 - val_loss: 9257077760.0000\n",
      "Epoch 381/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8849779712.0000 - val_loss: 9551718400.0000\n",
      "Epoch 382/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8526627328.0000 - val_loss: 9062556672.0000\n",
      "Epoch 383/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8404675584.0000 - val_loss: 8938611712.0000\n",
      "Epoch 384/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8499513856.0000 - val_loss: 9041454080.0000\n",
      "Epoch 385/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8430030336.0000 - val_loss: 8978448384.0000\n",
      "Epoch 386/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8333533696.0000 - val_loss: 8943060992.0000\n",
      "Epoch 387/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8431780864.0000 - val_loss: 8876847104.0000\n",
      "Epoch 388/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8310575616.0000 - val_loss: 9047004160.0000\n",
      "Epoch 389/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8362337792.0000 - val_loss: 9102787584.0000\n",
      "Epoch 390/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8420525568.0000 - val_loss: 9103619072.0000\n",
      "Epoch 391/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8453058048.0000 - val_loss: 9362889728.0000\n",
      "Epoch 392/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8509144576.0000 - val_loss: 8908863488.0000\n",
      "Epoch 393/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8587005440.0000 - val_loss: 8988515328.0000\n",
      "Epoch 394/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8384263680.0000 - val_loss: 9119107072.0000\n",
      "Epoch 395/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8295932416.0000 - val_loss: 8890722304.0000\n",
      "Epoch 396/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8368635392.0000 - val_loss: 8850699264.0000\n",
      "Epoch 397/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8463925760.0000 - val_loss: 9111310336.0000\n",
      "Epoch 398/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8349862912.0000 - val_loss: 9417701376.0000\n",
      "Epoch 399/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8485131776.0000 - val_loss: 8861369344.0000\n",
      "Epoch 400/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 6ms/step - loss: 8524222976.0000 - val_loss: 8890313728.0000\n",
      "Epoch 401/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8357997056.0000 - val_loss: 9013557248.0000\n",
      "Epoch 402/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8337792512.0000 - val_loss: 8949596160.0000\n",
      "Epoch 403/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8389972480.0000 - val_loss: 9209895936.0000\n",
      "Epoch 404/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8532946432.0000 - val_loss: 9141161984.0000\n",
      "Epoch 405/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8271763968.0000 - val_loss: 8943239168.0000\n",
      "Epoch 406/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8296641024.0000 - val_loss: 9030688768.0000\n",
      "Epoch 407/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8442665984.0000 - val_loss: 8874405888.0000\n",
      "Epoch 408/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8319107072.0000 - val_loss: 8870248448.0000\n",
      "Epoch 409/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8522236416.0000 - val_loss: 8855490560.0000\n",
      "Epoch 410/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8589688320.0000 - val_loss: 8895795200.0000\n",
      "Epoch 411/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8362779648.0000 - val_loss: 8853723136.0000\n",
      "Epoch 412/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8400324096.0000 - val_loss: 8841586688.0000\n",
      "Epoch 413/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8352040448.0000 - val_loss: 9463574528.0000\n",
      "Epoch 414/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8328002560.0000 - val_loss: 8866201600.0000\n",
      "Epoch 415/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8284361728.0000 - val_loss: 8821827584.0000\n",
      "Epoch 416/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8240785408.0000 - val_loss: 8839324672.0000\n",
      "Epoch 417/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8415826944.0000 - val_loss: 9383926784.0000\n",
      "Epoch 418/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8376994304.0000 - val_loss: 8929444864.0000\n",
      "Epoch 419/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8441878016.0000 - val_loss: 9740906496.0000\n",
      "Epoch 420/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8480756224.0000 - val_loss: 9492990976.0000\n",
      "Epoch 421/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8325585408.0000 - val_loss: 8884591616.0000\n",
      "Epoch 422/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8410322944.0000 - val_loss: 8799256576.0000\n",
      "Epoch 423/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8353229824.0000 - val_loss: 8821068800.0000\n",
      "Epoch 424/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8254107136.0000 - val_loss: 8980590592.0000\n",
      "Epoch 425/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8207684096.0000 - val_loss: 9548633088.0000\n",
      "Epoch 426/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8302370304.0000 - val_loss: 8837552128.0000\n",
      "Epoch 427/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8287930368.0000 - val_loss: 9081209856.0000\n",
      "Epoch 428/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8338596352.0000 - val_loss: 8952547328.0000\n",
      "Epoch 429/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8370241536.0000 - val_loss: 9038046208.0000\n",
      "Epoch 430/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8316213760.0000 - val_loss: 8911613952.0000\n",
      "Epoch 431/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8319794176.0000 - val_loss: 9413542912.0000\n",
      "Epoch 432/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8351081472.0000 - val_loss: 8813000704.0000\n",
      "Epoch 433/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8240010240.0000 - val_loss: 8783917056.0000\n",
      "Epoch 434/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8352139264.0000 - val_loss: 9063507968.0000\n",
      "Epoch 435/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8237120000.0000 - val_loss: 9535050752.0000\n",
      "Epoch 436/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8282345984.0000 - val_loss: 9407972352.0000\n",
      "Epoch 437/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8529947136.0000 - val_loss: 9476822016.0000\n",
      "Epoch 438/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8340599808.0000 - val_loss: 8828428288.0000\n",
      "Epoch 439/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8342322688.0000 - val_loss: 8864318464.0000\n",
      "Epoch 440/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8381780480.0000 - val_loss: 8787916800.0000\n",
      "Epoch 441/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8551512576.0000 - val_loss: 9709339648.0000\n",
      "Epoch 442/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8294674432.0000 - val_loss: 8954988544.0000\n",
      "Epoch 443/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8297020416.0000 - val_loss: 9224282112.0000\n",
      "Epoch 444/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8422669312.0000 - val_loss: 9626627072.0000\n",
      "Epoch 445/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8225546240.0000 - val_loss: 8800201728.0000\n",
      "Epoch 446/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8367099392.0000 - val_loss: 9494036480.0000\n",
      "Epoch 447/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8271406080.0000 - val_loss: 8909944832.0000\n",
      "Epoch 448/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8236409856.0000 - val_loss: 8867859456.0000\n",
      "Epoch 449/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8255569920.0000 - val_loss: 8773277696.0000\n",
      "Epoch 450/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8189504512.0000 - val_loss: 8806740992.0000\n",
      "Epoch 451/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8172775424.0000 - val_loss: 8826438656.0000\n",
      "Epoch 452/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8352266240.0000 - val_loss: 8884833280.0000\n",
      "Epoch 453/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8181766656.0000 - val_loss: 9028007936.0000\n",
      "Epoch 454/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8154827776.0000 - val_loss: 8822296576.0000\n",
      "Epoch 455/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8160502784.0000 - val_loss: 8743390208.0000\n",
      "Epoch 456/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8348929024.0000 - val_loss: 9080608768.0000\n",
      "Epoch 457/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8461345792.0000 - val_loss: 8877545472.0000\n",
      "Epoch 458/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8204333056.0000 - val_loss: 8943263744.0000\n",
      "Epoch 459/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8226386432.0000 - val_loss: 8854771712.0000\n",
      "Epoch 460/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8203530240.0000 - val_loss: 8786718720.0000\n",
      "Epoch 461/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8424320512.0000 - val_loss: 8953302016.0000\n",
      "Epoch 462/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8250555392.0000 - val_loss: 8755502080.0000\n",
      "Epoch 463/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8295076864.0000 - val_loss: 9684252672.0000\n",
      "Epoch 464/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8367754240.0000 - val_loss: 8972181504.0000\n",
      "Epoch 465/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8344549376.0000 - val_loss: 8736368640.0000\n",
      "Epoch 466/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8236508160.0000 - val_loss: 8759476224.0000\n",
      "Epoch 467/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8235708416.0000 - val_loss: 9018071040.0000\n",
      "Epoch 468/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8189744128.0000 - val_loss: 8979705856.0000\n",
      "Epoch 469/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8293239808.0000 - val_loss: 10019362816.0000\n",
      "Epoch 470/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8236707328.0000 - val_loss: 9236294656.0000\n",
      "Epoch 471/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8148384256.0000 - val_loss: 8720667648.0000\n",
      "Epoch 472/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8208665088.0000 - val_loss: 8772933632.0000\n",
      "Epoch 473/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8254199296.0000 - val_loss: 8988818432.0000\n",
      "Epoch 474/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8341769216.0000 - val_loss: 8735415296.0000\n",
      "Epoch 475/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8165139968.0000 - val_loss: 9161507840.0000\n",
      "Epoch 476/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8203686912.0000 - val_loss: 8807642112.0000\n",
      "Epoch 477/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8306869248.0000 - val_loss: 8839268352.0000\n",
      "Epoch 478/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8441187328.0000 - val_loss: 8779739136.0000\n",
      "Epoch 479/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8170742784.0000 - val_loss: 8866249728.0000\n",
      "Epoch 480/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8240176640.0000 - val_loss: 8720711680.0000\n",
      "Epoch 481/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8231245824.0000 - val_loss: 8732337152.0000\n",
      "Epoch 482/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8179950080.0000 - val_loss: 8823346176.0000\n",
      "Epoch 483/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8381009408.0000 - val_loss: 8999013376.0000\n",
      "Epoch 484/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8295398400.0000 - val_loss: 10513503232.0000\n",
      "Epoch 485/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8272774144.0000 - val_loss: 9094781952.0000\n",
      "Epoch 486/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8132086272.0000 - val_loss: 8808895488.0000\n",
      "Epoch 487/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8098224128.0000 - val_loss: 8877119488.0000\n",
      "Epoch 488/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8277326336.0000 - val_loss: 9107102720.0000\n",
      "Epoch 489/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8223472128.0000 - val_loss: 8702101504.0000\n",
      "Epoch 490/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8158948352.0000 - val_loss: 9017393152.0000\n",
      "Epoch 491/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8433743360.0000 - val_loss: 8895325184.0000\n",
      "Epoch 492/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8201147904.0000 - val_loss: 8692740096.0000\n",
      "Epoch 493/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8493215232.0000 - val_loss: 10665061376.0000\n",
      "Epoch 494/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8263732736.0000 - val_loss: 9490422784.0000\n",
      "Epoch 495/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8129880064.0000 - val_loss: 9093052416.0000\n",
      "Epoch 496/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8442968064.0000 - val_loss: 8724671488.0000\n",
      "Epoch 497/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8164552704.0000 - val_loss: 8801758208.0000\n",
      "Epoch 498/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8146482176.0000 - val_loss: 8681315328.0000\n",
      "Epoch 499/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8329454592.0000 - val_loss: 8709718016.0000\n",
      "Epoch 500/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8231614976.0000 - val_loss: 8774768640.0000\n",
      "Epoch 501/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8238837248.0000 - val_loss: 8794038272.0000\n",
      "Epoch 502/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8183578624.0000 - val_loss: 8811013120.0000\n",
      "Epoch 503/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8183428608.0000 - val_loss: 8797800448.0000\n",
      "Epoch 504/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8229743104.0000 - val_loss: 8816363520.0000\n",
      "Epoch 505/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8111675904.0000 - val_loss: 9481860096.0000\n",
      "Epoch 506/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8135069184.0000 - val_loss: 9030722560.0000\n",
      "Epoch 507/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8256132096.0000 - val_loss: 9427283968.0000\n",
      "Epoch 508/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8239672320.0000 - val_loss: 8829107200.0000\n",
      "Epoch 509/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8141342720.0000 - val_loss: 8842599424.0000\n",
      "Epoch 510/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8218263040.0000 - val_loss: 8744842240.0000\n",
      "Epoch 511/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8170468352.0000 - val_loss: 8711168000.0000\n",
      "Epoch 512/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8477637120.0000 - val_loss: 8759041024.0000\n",
      "Epoch 513/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8237809664.0000 - val_loss: 8750829568.0000\n",
      "Epoch 514/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8077700096.0000 - val_loss: 8685752320.0000\n",
      "Epoch 515/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8048877056.0000 - val_loss: 8780214272.0000\n",
      "Epoch 516/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8173356544.0000 - val_loss: 8786570240.0000\n",
      "Epoch 517/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8045245440.0000 - val_loss: 8672562176.0000\n",
      "Epoch 518/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8068891648.0000 - val_loss: 8694781952.0000\n",
      "Epoch 519/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8145003008.0000 - val_loss: 8907357184.0000\n",
      "Epoch 520/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8090363392.0000 - val_loss: 8739974144.0000\n",
      "Epoch 521/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8111201792.0000 - val_loss: 9047914496.0000\n",
      "Epoch 522/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8161739264.0000 - val_loss: 8786714624.0000\n",
      "Epoch 523/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8242378240.0000 - val_loss: 9134040064.0000\n",
      "Epoch 524/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8295752192.0000 - val_loss: 9408904192.0000\n",
      "Epoch 525/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8128512000.0000 - val_loss: 8684296192.0000\n",
      "Epoch 526/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8194009600.0000 - val_loss: 9246961664.0000\n",
      "Epoch 527/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8230197760.0000 - val_loss: 8667816960.0000\n",
      "Epoch 528/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8217750528.0000 - val_loss: 9738290176.0000\n",
      "Epoch 529/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8109841920.0000 - val_loss: 8672018432.0000\n",
      "Epoch 530/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8264100352.0000 - val_loss: 8905614336.0000\n",
      "Epoch 531/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8315612160.0000 - val_loss: 8757103616.0000\n",
      "Epoch 532/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8133584384.0000 - val_loss: 9209411584.0000\n",
      "Epoch 533/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8081985536.0000 - val_loss: 8793291776.0000\n",
      "Epoch 534/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 6ms/step - loss: 8009378816.0000 - val_loss: 8938792960.0000\n",
      "Epoch 535/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8369370624.0000 - val_loss: 8695746560.0000\n",
      "Epoch 536/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8097477632.0000 - val_loss: 8845101056.0000\n",
      "Epoch 537/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8062539264.0000 - val_loss: 9338424320.0000\n",
      "Epoch 538/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8307270144.0000 - val_loss: 9105875968.0000\n",
      "Epoch 539/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8128902144.0000 - val_loss: 8884715520.0000\n",
      "Epoch 540/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8237264896.0000 - val_loss: 8733649920.0000\n",
      "Epoch 541/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8114409472.0000 - val_loss: 8637057024.0000\n",
      "Epoch 542/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8153354240.0000 - val_loss: 8701008896.0000\n",
      "Epoch 543/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8029175296.0000 - val_loss: 8636020736.0000\n",
      "Epoch 544/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8071430656.0000 - val_loss: 9438825472.0000\n",
      "Epoch 545/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8105699328.0000 - val_loss: 8941437952.0000\n",
      "Epoch 546/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8108541440.0000 - val_loss: 9141891072.0000\n",
      "Epoch 547/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8185807360.0000 - val_loss: 8658136064.0000\n",
      "Epoch 548/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8175846912.0000 - val_loss: 9807271936.0000\n",
      "Epoch 549/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8163497472.0000 - val_loss: 8719790080.0000\n",
      "Epoch 550/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8106604032.0000 - val_loss: 8643317760.0000\n",
      "Epoch 551/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8140398080.0000 - val_loss: 8689129472.0000\n",
      "Epoch 552/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8050848256.0000 - val_loss: 8642523136.0000\n",
      "Epoch 553/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8134630400.0000 - val_loss: 8729102336.0000\n",
      "Epoch 554/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8124508160.0000 - val_loss: 9683614720.0000\n",
      "Epoch 555/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8537007616.0000 - val_loss: 10023908352.0000\n",
      "Epoch 556/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8146365952.0000 - val_loss: 8609895424.0000\n",
      "Epoch 557/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8050916352.0000 - val_loss: 8674683904.0000\n",
      "Epoch 558/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8054621184.0000 - val_loss: 8890559488.0000\n",
      "Epoch 559/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7988448768.0000 - val_loss: 8600031232.0000\n",
      "Epoch 560/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8138136576.0000 - val_loss: 8726074368.0000\n",
      "Epoch 561/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8208869888.0000 - val_loss: 9117802496.0000\n",
      "Epoch 562/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8106931200.0000 - val_loss: 8739540992.0000\n",
      "Epoch 563/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8053730304.0000 - val_loss: 8633814016.0000\n",
      "Epoch 564/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8159687168.0000 - val_loss: 8739098624.0000\n",
      "Epoch 565/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8033168384.0000 - val_loss: 8614691840.0000\n",
      "Epoch 566/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8297758720.0000 - val_loss: 9124950016.0000\n",
      "Epoch 567/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8049250304.0000 - val_loss: 8611104768.0000\n",
      "Epoch 568/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8119165952.0000 - val_loss: 8634135552.0000\n",
      "Epoch 569/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8196438016.0000 - val_loss: 8593739776.0000\n",
      "Epoch 570/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8170334208.0000 - val_loss: 9329772544.0000\n",
      "Epoch 571/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8135194112.0000 - val_loss: 8913669120.0000\n",
      "Epoch 572/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8023192064.0000 - val_loss: 8585086464.0000\n",
      "Epoch 573/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8019776000.0000 - val_loss: 9493599232.0000\n",
      "Epoch 574/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8143745536.0000 - val_loss: 8628084736.0000\n",
      "Epoch 575/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8000925696.0000 - val_loss: 8654011392.0000\n",
      "Epoch 576/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8229587456.0000 - val_loss: 8655080448.0000\n",
      "Epoch 577/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8295485440.0000 - val_loss: 8669893632.0000\n",
      "Epoch 578/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8010453504.0000 - val_loss: 8701136896.0000\n",
      "Epoch 579/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8270512640.0000 - val_loss: 9081955328.0000\n",
      "Epoch 580/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8067972096.0000 - val_loss: 8945646592.0000\n",
      "Epoch 581/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8065565696.0000 - val_loss: 8741936128.0000\n",
      "Epoch 582/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8104032768.0000 - val_loss: 8744769536.0000\n",
      "Epoch 583/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8050541056.0000 - val_loss: 9026211840.0000\n",
      "Epoch 584/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8073399808.0000 - val_loss: 8594973696.0000\n",
      "Epoch 585/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8052198400.0000 - val_loss: 9212309504.0000\n",
      "Epoch 586/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8069720064.0000 - val_loss: 8620138496.0000\n",
      "Epoch 587/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8191460864.0000 - val_loss: 8605086720.0000\n",
      "Epoch 588/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8060317184.0000 - val_loss: 8686245888.0000\n",
      "Epoch 589/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7948937216.0000 - val_loss: 8914111488.0000\n",
      "Epoch 590/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7988363264.0000 - val_loss: 8678878208.0000\n",
      "Epoch 591/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8048969216.0000 - val_loss: 9252694016.0000\n",
      "Epoch 592/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8052470784.0000 - val_loss: 8587154944.0000\n",
      "Epoch 593/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7973699072.0000 - val_loss: 9303004160.0000\n",
      "Epoch 594/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8036441600.0000 - val_loss: 8729692160.0000\n",
      "Epoch 595/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8018706432.0000 - val_loss: 8963080192.0000\n",
      "Epoch 596/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8030114304.0000 - val_loss: 8686349312.0000\n",
      "Epoch 597/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8033969664.0000 - val_loss: 8653555712.0000\n",
      "Epoch 598/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8247331328.0000 - val_loss: 8861069312.0000\n",
      "Epoch 599/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8121701376.0000 - val_loss: 8760459264.0000\n",
      "Epoch 600/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7992494080.0000 - val_loss: 8610404352.0000\n",
      "Epoch 601/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8055505920.0000 - val_loss: 8833582080.0000\n",
      "Epoch 602/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8099817984.0000 - val_loss: 8567323648.0000\n",
      "Epoch 603/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8248843264.0000 - val_loss: 8743240704.0000\n",
      "Epoch 604/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7952456704.0000 - val_loss: 9362766848.0000\n",
      "Epoch 605/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8193860096.0000 - val_loss: 8795789312.0000\n",
      "Epoch 606/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8014322176.0000 - val_loss: 8568142336.0000\n",
      "Epoch 607/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8010636288.0000 - val_loss: 8639374336.0000\n",
      "Epoch 608/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8046917120.0000 - val_loss: 8773469184.0000\n",
      "Epoch 609/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8083393024.0000 - val_loss: 8615293952.0000\n",
      "Epoch 610/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7930452992.0000 - val_loss: 8884920320.0000\n",
      "Epoch 611/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8021274112.0000 - val_loss: 8689117184.0000\n",
      "Epoch 612/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7912472064.0000 - val_loss: 8979095552.0000\n",
      "Epoch 613/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8041153024.0000 - val_loss: 8686386176.0000\n",
      "Epoch 614/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7925785088.0000 - val_loss: 8609848320.0000\n",
      "Epoch 615/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7995556864.0000 - val_loss: 8668121088.0000\n",
      "Epoch 616/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8016463360.0000 - val_loss: 8532030976.0000\n",
      "Epoch 617/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7933642752.0000 - val_loss: 8567031808.0000\n",
      "Epoch 618/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7995165184.0000 - val_loss: 9570804736.0000\n",
      "Epoch 619/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8143123968.0000 - val_loss: 8619130880.0000\n",
      "Epoch 620/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8095504896.0000 - val_loss: 8620011520.0000\n",
      "Epoch 621/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7953392640.0000 - val_loss: 8590476288.0000\n",
      "Epoch 622/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7936790528.0000 - val_loss: 8569741312.0000\n",
      "Epoch 623/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8039177216.0000 - val_loss: 9692083200.0000\n",
      "Epoch 624/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8060315136.0000 - val_loss: 8659095552.0000\n",
      "Epoch 625/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7989106688.0000 - val_loss: 8660088832.0000\n",
      "Epoch 626/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7909930496.0000 - val_loss: 8622844928.0000\n",
      "Epoch 627/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7971593216.0000 - val_loss: 8975368192.0000\n",
      "Epoch 628/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8020064768.0000 - val_loss: 10340024320.0000\n",
      "Epoch 629/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8035338240.0000 - val_loss: 9478915072.0000\n",
      "Epoch 630/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7907706368.0000 - val_loss: 8844865536.0000\n",
      "Epoch 631/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7982411264.0000 - val_loss: 9185684480.0000\n",
      "Epoch 632/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8161458688.0000 - val_loss: 8587595776.0000\n",
      "Epoch 633/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7886072320.0000 - val_loss: 8574185984.0000\n",
      "Epoch 634/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7951506432.0000 - val_loss: 8580975104.0000\n",
      "Epoch 635/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7959321600.0000 - val_loss: 8738216960.0000\n",
      "Epoch 636/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7943110656.0000 - val_loss: 8722822144.0000\n",
      "Epoch 637/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8042390528.0000 - val_loss: 9345712128.0000\n",
      "Epoch 638/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7914754560.0000 - val_loss: 8754642944.0000\n",
      "Epoch 639/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8020443648.0000 - val_loss: 8799050752.0000\n",
      "Epoch 640/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7998250496.0000 - val_loss: 8653878272.0000\n",
      "Epoch 641/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8148071424.0000 - val_loss: 8556824576.0000\n",
      "Epoch 642/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7941568000.0000 - val_loss: 8708147200.0000\n",
      "Epoch 643/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8038876672.0000 - val_loss: 8575470592.0000\n",
      "Epoch 644/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7939875840.0000 - val_loss: 8761198592.0000\n",
      "Epoch 645/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7914759168.0000 - val_loss: 8650114048.0000\n",
      "Epoch 646/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8082797568.0000 - val_loss: 8917785600.0000\n",
      "Epoch 647/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7965500928.0000 - val_loss: 8593305600.0000\n",
      "Epoch 648/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8120053760.0000 - val_loss: 12402966528.0000\n",
      "Epoch 649/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8251016192.0000 - val_loss: 8806670336.0000\n",
      "Epoch 650/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8370759168.0000 - val_loss: 9067171840.0000\n",
      "Epoch 651/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8034660864.0000 - val_loss: 8597814272.0000\n",
      "Epoch 652/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7904584704.0000 - val_loss: 8507304448.0000\n",
      "Epoch 653/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7848936960.0000 - val_loss: 8652918784.0000\n",
      "Epoch 654/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8025551360.0000 - val_loss: 8550819840.0000\n",
      "Epoch 655/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7868548096.0000 - val_loss: 8694971392.0000\n",
      "Epoch 656/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7908874240.0000 - val_loss: 9236102144.0000\n",
      "Epoch 657/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7924784640.0000 - val_loss: 8557391872.0000\n",
      "Epoch 658/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7976332800.0000 - val_loss: 8494980608.0000\n",
      "Epoch 659/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8179617280.0000 - val_loss: 8585353728.0000\n",
      "Epoch 660/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8183477248.0000 - val_loss: 8554995200.0000\n",
      "Epoch 661/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8075720704.0000 - val_loss: 9716842496.0000\n",
      "Epoch 662/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8018953728.0000 - val_loss: 8610081792.0000\n",
      "Epoch 663/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7956593664.0000 - val_loss: 9198922752.0000\n",
      "Epoch 664/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7976358400.0000 - val_loss: 8599122944.0000\n",
      "Epoch 665/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8045562880.0000 - val_loss: 8510209024.0000\n",
      "Epoch 666/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7969041920.0000 - val_loss: 8803287040.0000\n",
      "Epoch 667/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7931018240.0000 - val_loss: 8968565760.0000\n",
      "Epoch 668/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 7ms/step - loss: 7897420800.0000 - val_loss: 8526927360.0000\n",
      "Epoch 669/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7964977152.0000 - val_loss: 8486492672.0000\n",
      "Epoch 670/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8152602624.0000 - val_loss: 8495751168.0000\n",
      "Epoch 671/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8074969600.0000 - val_loss: 8755454976.0000\n",
      "Epoch 672/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7995784704.0000 - val_loss: 9001160704.0000\n",
      "Epoch 673/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7930893824.0000 - val_loss: 8500511232.0000\n",
      "Epoch 674/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7923143680.0000 - val_loss: 8687628288.0000\n",
      "Epoch 675/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7926572032.0000 - val_loss: 9341496320.0000\n",
      "Epoch 676/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7889650176.0000 - val_loss: 9273473024.0000\n",
      "Epoch 677/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7953222656.0000 - val_loss: 8497825280.0000\n",
      "Epoch 678/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7937836544.0000 - val_loss: 8648522752.0000\n",
      "Epoch 679/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8162879488.0000 - val_loss: 8655355904.0000\n",
      "Epoch 680/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7833902592.0000 - val_loss: 8559477760.0000\n",
      "Epoch 681/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7964920320.0000 - val_loss: 8862007296.0000\n",
      "Epoch 682/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7924644864.0000 - val_loss: 8480174080.0000\n",
      "Epoch 683/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7878194176.0000 - val_loss: 8513861120.0000\n",
      "Epoch 684/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7900082688.0000 - val_loss: 8603604992.0000\n",
      "Epoch 685/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8037644800.0000 - val_loss: 8540534272.0000\n",
      "Epoch 686/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7944379392.0000 - val_loss: 9254038528.0000\n",
      "Epoch 687/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7803320832.0000 - val_loss: 9146627072.0000\n",
      "Epoch 688/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8054391296.0000 - val_loss: 8595381248.0000\n",
      "Epoch 689/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7939374592.0000 - val_loss: 8691705856.0000\n",
      "Epoch 690/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7889460736.0000 - val_loss: 8530804736.0000\n",
      "Epoch 691/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7855409664.0000 - val_loss: 8478023680.0000\n",
      "Epoch 692/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7984332800.0000 - val_loss: 8649869312.0000\n",
      "Epoch 693/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7942286848.0000 - val_loss: 9023757312.0000\n",
      "Epoch 694/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7942991872.0000 - val_loss: 8520708096.0000\n",
      "Epoch 695/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7982631424.0000 - val_loss: 8471807488.0000\n",
      "Epoch 696/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7925293056.0000 - val_loss: 8472901632.0000\n",
      "Epoch 697/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7943564800.0000 - val_loss: 8575264256.0000\n",
      "Epoch 698/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7965042176.0000 - val_loss: 8499613184.0000\n",
      "Epoch 699/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8002428928.0000 - val_loss: 8491908096.0000\n",
      "Epoch 700/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7840765952.0000 - val_loss: 9062865920.0000\n",
      "Epoch 701/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7846716928.0000 - val_loss: 8715296768.0000\n",
      "Epoch 702/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7938401792.0000 - val_loss: 8700965888.0000\n",
      "Epoch 703/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7908787712.0000 - val_loss: 8586604544.0000\n",
      "Epoch 704/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7916858368.0000 - val_loss: 8533081600.0000\n",
      "Epoch 705/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7770796544.0000 - val_loss: 8848024576.0000\n",
      "Epoch 706/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7901985792.0000 - val_loss: 8498870272.0000\n",
      "Epoch 707/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7800957952.0000 - val_loss: 8665734144.0000\n",
      "Epoch 708/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7906345984.0000 - val_loss: 8454309888.0000\n",
      "Epoch 709/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7793997312.0000 - val_loss: 8475556352.0000\n",
      "Epoch 710/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7859046400.0000 - val_loss: 8489864192.0000\n",
      "Epoch 711/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7928755712.0000 - val_loss: 8611432448.0000\n",
      "Epoch 712/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8034421760.0000 - val_loss: 8728924160.0000\n",
      "Epoch 713/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7847978496.0000 - val_loss: 8783524864.0000\n",
      "Epoch 714/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7972687360.0000 - val_loss: 8465641984.0000\n",
      "Epoch 715/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8112180736.0000 - val_loss: 8469956608.0000\n",
      "Epoch 716/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7893358080.0000 - val_loss: 8779277312.0000\n",
      "Epoch 717/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7845174272.0000 - val_loss: 8562930688.0000\n",
      "Epoch 718/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7833063424.0000 - val_loss: 8464544768.0000\n",
      "Epoch 719/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8063386624.0000 - val_loss: 8662652928.0000\n",
      "Epoch 720/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7815889408.0000 - val_loss: 8449830912.0000\n",
      "Epoch 721/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7889539072.0000 - val_loss: 8483542528.0000\n",
      "Epoch 722/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7924623872.0000 - val_loss: 8761818112.0000\n",
      "Epoch 723/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7882008576.0000 - val_loss: 8707878912.0000\n",
      "Epoch 724/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7908335616.0000 - val_loss: 8845542400.0000\n",
      "Epoch 725/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7842208256.0000 - val_loss: 9059031040.0000\n",
      "Epoch 726/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7969117184.0000 - val_loss: 8727513088.0000\n",
      "Epoch 727/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7909713408.0000 - val_loss: 8567716864.0000\n",
      "Epoch 728/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7936157696.0000 - val_loss: 8484598784.0000\n",
      "Epoch 729/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8056551424.0000 - val_loss: 8489861120.0000\n",
      "Epoch 730/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7889423872.0000 - val_loss: 8502000128.0000\n",
      "Epoch 731/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7827127296.0000 - val_loss: 9896646656.0000\n",
      "Epoch 732/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7972324864.0000 - val_loss: 8736576512.0000\n",
      "Epoch 733/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7847875584.0000 - val_loss: 8480603648.0000\n",
      "Epoch 734/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7996708352.0000 - val_loss: 9291601920.0000\n",
      "Epoch 735/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8018753536.0000 - val_loss: 8517617152.0000\n",
      "Epoch 736/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7895665152.0000 - val_loss: 8502733312.0000\n",
      "Epoch 737/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8198767616.0000 - val_loss: 9181042688.0000\n",
      "Epoch 738/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7910649856.0000 - val_loss: 8536707072.0000\n",
      "Epoch 739/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7815262208.0000 - val_loss: 8797947904.0000\n",
      "Epoch 740/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7786794496.0000 - val_loss: 8437848064.0000\n",
      "Epoch 741/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7969220096.0000 - val_loss: 8997653504.0000\n",
      "Epoch 742/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7796706816.0000 - val_loss: 8566311936.0000\n",
      "Epoch 743/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7957971968.0000 - val_loss: 10119145472.0000\n",
      "Epoch 744/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7997252096.0000 - val_loss: 8477397504.0000\n",
      "Epoch 745/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7742243840.0000 - val_loss: 8925240320.0000\n",
      "Epoch 746/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8008595968.0000 - val_loss: 8661746688.0000\n",
      "Epoch 747/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7832691712.0000 - val_loss: 8458611712.0000\n",
      "Epoch 748/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7760434688.0000 - val_loss: 8477986304.0000\n",
      "Epoch 749/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8015524352.0000 - val_loss: 9087842304.0000\n",
      "Epoch 750/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7840902656.0000 - val_loss: 8468836352.0000\n",
      "Epoch 751/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7799453696.0000 - val_loss: 8635321344.0000\n",
      "Epoch 752/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7877316096.0000 - val_loss: 8495848448.0000\n",
      "Epoch 753/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7928674816.0000 - val_loss: 8484077568.0000\n",
      "Epoch 754/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7820234752.0000 - val_loss: 8655623168.0000\n",
      "Epoch 755/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7884417024.0000 - val_loss: 8476297728.0000\n",
      "Epoch 756/1500\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 7893753856.0000 - val_loss: 8537518080.0000\n",
      "Epoch 757/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7975342080.0000 - val_loss: 9443182592.0000\n",
      "Epoch 758/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7951876608.0000 - val_loss: 8448336384.0000\n",
      "Epoch 759/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7868092416.0000 - val_loss: 8791915520.0000\n",
      "Epoch 760/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7902904320.0000 - val_loss: 8720206848.0000\n",
      "Epoch 761/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7766382080.0000 - val_loss: 9234299904.0000\n",
      "Epoch 762/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8029003264.0000 - val_loss: 8441736192.0000\n",
      "Epoch 763/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7827130880.0000 - val_loss: 8405835776.0000\n",
      "Epoch 764/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7729342464.0000 - val_loss: 8533376000.0000\n",
      "Epoch 765/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8151273472.0000 - val_loss: 8476110848.0000\n",
      "Epoch 766/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7733911040.0000 - val_loss: 8661996544.0000\n",
      "Epoch 767/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7793384448.0000 - val_loss: 8499031552.0000\n",
      "Epoch 768/1500\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 7854411776.0000 - val_loss: 8407087616.0000\n",
      "Epoch 769/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7762727424.0000 - val_loss: 8445570560.0000\n",
      "Epoch 770/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7942468096.0000 - val_loss: 9365145600.0000\n",
      "Epoch 771/1500\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 7897676288.0000 - val_loss: 8594320384.0000\n",
      "Epoch 772/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7714730496.0000 - val_loss: 8431582720.0000\n",
      "Epoch 773/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7756845568.0000 - val_loss: 8459631104.0000\n",
      "Epoch 774/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7715294720.0000 - val_loss: 8547600896.0000\n",
      "Epoch 775/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8161548800.0000 - val_loss: 9358941184.0000\n",
      "Epoch 776/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7964337664.0000 - val_loss: 8403996160.0000\n",
      "Epoch 777/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7748485120.0000 - val_loss: 8485405184.0000\n",
      "Epoch 778/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7922988544.0000 - val_loss: 9060832256.0000\n",
      "Epoch 779/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7790623744.0000 - val_loss: 8447926272.0000\n",
      "Epoch 780/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8008749056.0000 - val_loss: 8777803776.0000\n",
      "Epoch 781/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7912537600.0000 - val_loss: 9616880640.0000\n",
      "Epoch 782/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8083256832.0000 - val_loss: 8673828864.0000\n",
      "Epoch 783/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7870234112.0000 - val_loss: 9595232256.0000\n",
      "Epoch 784/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7816219136.0000 - val_loss: 8503324160.0000\n",
      "Epoch 785/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7887295488.0000 - val_loss: 8688195584.0000\n",
      "Epoch 786/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7879652864.0000 - val_loss: 8546885632.0000\n",
      "Epoch 787/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7761547776.0000 - val_loss: 8414769664.0000\n",
      "Epoch 788/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7930845184.0000 - val_loss: 8768692224.0000\n",
      "Epoch 789/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7800451584.0000 - val_loss: 10232321024.0000\n",
      "Epoch 790/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7914898432.0000 - val_loss: 8435398144.0000\n",
      "Epoch 791/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7798225408.0000 - val_loss: 8589201408.0000\n",
      "Epoch 792/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7894503424.0000 - val_loss: 8638075904.0000\n",
      "Epoch 793/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7834750976.0000 - val_loss: 8849997824.0000\n",
      "Epoch 794/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7819618816.0000 - val_loss: 8567360512.0000\n",
      "Epoch 795/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7801673728.0000 - val_loss: 9453886464.0000\n",
      "Epoch 796/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7809930752.0000 - val_loss: 8449573888.0000\n",
      "Epoch 797/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7880623104.0000 - val_loss: 9107138560.0000\n",
      "Epoch 798/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7820305920.0000 - val_loss: 9500289024.0000\n",
      "Epoch 799/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7789382144.0000 - val_loss: 8763455488.0000\n",
      "Epoch 800/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7831728640.0000 - val_loss: 8396642816.0000\n",
      "Epoch 801/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7764431360.0000 - val_loss: 8513255424.0000\n",
      "Epoch 802/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 6ms/step - loss: 7822729728.0000 - val_loss: 8410481664.0000\n",
      "Epoch 803/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7732517888.0000 - val_loss: 8878417920.0000\n",
      "Epoch 804/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7959742976.0000 - val_loss: 9031369728.0000\n",
      "Epoch 805/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7760051712.0000 - val_loss: 8473430528.0000\n",
      "Epoch 806/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7686572544.0000 - val_loss: 8829528064.0000\n",
      "Epoch 807/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7806555136.0000 - val_loss: 8574099456.0000\n",
      "Epoch 808/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7791800320.0000 - val_loss: 8499779072.0000\n",
      "Epoch 809/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7827034112.0000 - val_loss: 8620874752.0000\n",
      "Epoch 810/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7902154752.0000 - val_loss: 8468052480.0000\n",
      "Epoch 811/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7867151360.0000 - val_loss: 8496157184.0000\n",
      "Epoch 812/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7765035008.0000 - val_loss: 8434225664.0000\n",
      "Epoch 813/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7727451136.0000 - val_loss: 8810008576.0000\n",
      "Epoch 814/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7752728064.0000 - val_loss: 8461988352.0000\n",
      "Epoch 815/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7809644032.0000 - val_loss: 8580901376.0000\n",
      "Epoch 816/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7810911232.0000 - val_loss: 9522010112.0000\n",
      "Epoch 817/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7775899136.0000 - val_loss: 8407510528.0000\n",
      "Epoch 818/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7816158208.0000 - val_loss: 8580609024.0000\n",
      "Epoch 819/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7793000448.0000 - val_loss: 8524950528.0000\n",
      "Epoch 820/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7861987328.0000 - val_loss: 8521456128.0000\n",
      "Epoch 821/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7755776512.0000 - val_loss: 8624979968.0000\n",
      "Epoch 822/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7760079360.0000 - val_loss: 8405749760.0000\n",
      "Epoch 823/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7797285888.0000 - val_loss: 8536208896.0000\n",
      "Epoch 824/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7793602560.0000 - val_loss: 8944405504.0000\n",
      "Epoch 825/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7822372352.0000 - val_loss: 8680249344.0000\n",
      "Epoch 826/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7841529856.0000 - val_loss: 8531956736.0000\n",
      "Epoch 827/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7720398336.0000 - val_loss: 8565297664.0000\n",
      "Epoch 828/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7782174720.0000 - val_loss: 8631372800.0000\n",
      "Epoch 829/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8066196480.0000 - val_loss: 8932047872.0000\n",
      "Epoch 830/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7998643200.0000 - val_loss: 8728145920.0000\n",
      "Epoch 831/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7712268288.0000 - val_loss: 8465220608.0000\n",
      "Epoch 832/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7780550656.0000 - val_loss: 8372748288.0000\n",
      "Epoch 833/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7739767296.0000 - val_loss: 8485250048.0000\n",
      "Epoch 834/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7723649024.0000 - val_loss: 8926461952.0000\n",
      "Epoch 835/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7973840896.0000 - val_loss: 8415809024.0000\n",
      "Epoch 836/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7768342016.0000 - val_loss: 8437824512.0000\n",
      "Epoch 837/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7815570944.0000 - val_loss: 8774667264.0000\n",
      "Epoch 838/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7793312256.0000 - val_loss: 9466692608.0000\n",
      "Epoch 839/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7924212224.0000 - val_loss: 8367007232.0000\n",
      "Epoch 840/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7848166912.0000 - val_loss: 8408522240.0000\n",
      "Epoch 841/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7726619648.0000 - val_loss: 9331899392.0000\n",
      "Epoch 842/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7726849536.0000 - val_loss: 8479029248.0000\n",
      "Epoch 843/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7821075968.0000 - val_loss: 8598636544.0000\n",
      "Epoch 844/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7757488128.0000 - val_loss: 9106604032.0000\n",
      "Epoch 845/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7771683840.0000 - val_loss: 9455335424.0000\n",
      "Epoch 846/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7779131904.0000 - val_loss: 9082527744.0000\n",
      "Epoch 847/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7717917184.0000 - val_loss: 8488677376.0000\n",
      "Epoch 848/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8084073984.0000 - val_loss: 9125330944.0000\n",
      "Epoch 849/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7723717632.0000 - val_loss: 8827180032.0000\n",
      "Epoch 850/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7715063808.0000 - val_loss: 8736211968.0000\n",
      "Epoch 851/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7792909312.0000 - val_loss: 8494707200.0000\n",
      "Epoch 852/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7765321728.0000 - val_loss: 8500572160.0000\n",
      "Epoch 853/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7822037504.0000 - val_loss: 8395689472.0000\n",
      "Epoch 854/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7791698944.0000 - val_loss: 8527613952.0000\n",
      "Epoch 855/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7694062592.0000 - val_loss: 8345738240.0000\n",
      "Epoch 856/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7730181632.0000 - val_loss: 8431345152.0000\n",
      "Epoch 857/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7989966336.0000 - val_loss: 8938131456.0000\n",
      "Epoch 858/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7799677440.0000 - val_loss: 8507729408.0000\n",
      "Epoch 859/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7803796480.0000 - val_loss: 8334175232.0000\n",
      "Epoch 860/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7990918656.0000 - val_loss: 8885687296.0000\n",
      "Epoch 861/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7710516736.0000 - val_loss: 8394555904.0000\n",
      "Epoch 862/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7866204672.0000 - val_loss: 9865748480.0000\n",
      "Epoch 863/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7883774976.0000 - val_loss: 8366155776.0000\n",
      "Epoch 864/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7873044992.0000 - val_loss: 8738967552.0000\n",
      "Epoch 865/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7902678016.0000 - val_loss: 9436125184.0000\n",
      "Epoch 866/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7785445888.0000 - val_loss: 8425718784.0000\n",
      "Epoch 867/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7625923584.0000 - val_loss: 8718069760.0000\n",
      "Epoch 868/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7774942208.0000 - val_loss: 8822756352.0000\n",
      "Epoch 869/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7783271424.0000 - val_loss: 8340425216.0000\n",
      "Epoch 870/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7841971712.0000 - val_loss: 8444964864.0000\n",
      "Epoch 871/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7725045760.0000 - val_loss: 8403304448.0000\n",
      "Epoch 872/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7761008128.0000 - val_loss: 8479326720.0000\n",
      "Epoch 873/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7658533376.0000 - val_loss: 8436537344.0000\n",
      "Epoch 874/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7674297856.0000 - val_loss: 8783745024.0000\n",
      "Epoch 875/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7722763776.0000 - val_loss: 9210216448.0000\n",
      "Epoch 876/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7877009920.0000 - val_loss: 8498678784.0000\n",
      "Epoch 877/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7749969408.0000 - val_loss: 8434563072.0000\n",
      "Epoch 878/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7672606208.0000 - val_loss: 8500426240.0000\n",
      "Epoch 879/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7884673536.0000 - val_loss: 8546814464.0000\n",
      "Epoch 880/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7745591296.0000 - val_loss: 8595723264.0000\n",
      "Epoch 881/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7769762304.0000 - val_loss: 9222076416.0000\n",
      "Epoch 882/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7835222016.0000 - val_loss: 8562083840.0000\n",
      "Epoch 883/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7668106240.0000 - val_loss: 8361028096.0000\n",
      "Epoch 884/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7654190080.0000 - val_loss: 8540439552.0000\n",
      "Epoch 885/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7639018496.0000 - val_loss: 8672565248.0000\n",
      "Epoch 886/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7628333056.0000 - val_loss: 8457076224.0000\n",
      "Epoch 887/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8246126592.0000 - val_loss: 8557078016.0000\n",
      "Epoch 888/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7910013952.0000 - val_loss: 8542561280.0000\n",
      "Epoch 889/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7781466112.0000 - val_loss: 8339092992.0000\n",
      "Epoch 890/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7902894592.0000 - val_loss: 8428477440.0000\n",
      "Epoch 891/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7669660672.0000 - val_loss: 8369759744.0000\n",
      "Epoch 892/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7777660416.0000 - val_loss: 8410284544.0000\n",
      "Epoch 893/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7680788992.0000 - val_loss: 8468130304.0000\n",
      "Epoch 894/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7593764864.0000 - val_loss: 8539466752.0000\n",
      "Epoch 895/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7759090688.0000 - val_loss: 8416564736.0000\n",
      "Epoch 896/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7744698368.0000 - val_loss: 8358386176.0000\n",
      "Epoch 897/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7665607168.0000 - val_loss: 10418361344.0000\n",
      "Epoch 898/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7855510016.0000 - val_loss: 8838283264.0000\n",
      "Epoch 899/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7673538560.0000 - val_loss: 8463503872.0000\n",
      "Epoch 900/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7703934976.0000 - val_loss: 8325492736.0000\n",
      "Epoch 901/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7651111424.0000 - val_loss: 8579424256.0000\n",
      "Epoch 902/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7836932096.0000 - val_loss: 8351069696.0000\n",
      "Epoch 903/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7896107008.0000 - val_loss: 9065549824.0000\n",
      "Epoch 904/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7703861248.0000 - val_loss: 8509109760.0000\n",
      "Epoch 905/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7769166336.0000 - val_loss: 8710010880.0000\n",
      "Epoch 906/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7749164032.0000 - val_loss: 8565620736.0000\n",
      "Epoch 907/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7629793280.0000 - val_loss: 8546045952.0000\n",
      "Epoch 908/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7749103104.0000 - val_loss: 8613320704.0000\n",
      "Epoch 909/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7652775424.0000 - val_loss: 8454411776.0000\n",
      "Epoch 910/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7857075200.0000 - val_loss: 8358846464.0000\n",
      "Epoch 911/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7706008576.0000 - val_loss: 8506704384.0000\n",
      "Epoch 912/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7885428736.0000 - val_loss: 8342707200.0000\n",
      "Epoch 913/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7706308096.0000 - val_loss: 8703501312.0000\n",
      "Epoch 914/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7695558144.0000 - val_loss: 8609186816.0000\n",
      "Epoch 915/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7891981824.0000 - val_loss: 8983555072.0000\n",
      "Epoch 916/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7836533248.0000 - val_loss: 8415749120.0000\n",
      "Epoch 917/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7613804544.0000 - val_loss: 8313487872.0000\n",
      "Epoch 918/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7677114880.0000 - val_loss: 8321414656.0000\n",
      "Epoch 919/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7734867968.0000 - val_loss: 8557123584.0000\n",
      "Epoch 920/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7589241344.0000 - val_loss: 8424889856.0000\n",
      "Epoch 921/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7706129408.0000 - val_loss: 8376096768.0000\n",
      "Epoch 922/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7949523456.0000 - val_loss: 8384834048.0000\n",
      "Epoch 923/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7635171328.0000 - val_loss: 8431806464.0000\n",
      "Epoch 924/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7821467648.0000 - val_loss: 8405538816.0000\n",
      "Epoch 925/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7684722176.0000 - val_loss: 8658876416.0000\n",
      "Epoch 926/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7708720128.0000 - val_loss: 8508389376.0000\n",
      "Epoch 927/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7742051328.0000 - val_loss: 8473984000.0000\n",
      "Epoch 928/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7750860288.0000 - val_loss: 8787232768.0000\n",
      "Epoch 929/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7617658368.0000 - val_loss: 8580816384.0000\n",
      "Epoch 930/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7734520832.0000 - val_loss: 8350338560.0000\n",
      "Epoch 931/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7910670336.0000 - val_loss: 8503494144.0000\n",
      "Epoch 932/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7646683136.0000 - val_loss: 8310125568.0000\n",
      "Epoch 933/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7839063552.0000 - val_loss: 8428113920.0000\n",
      "Epoch 934/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7723695104.0000 - val_loss: 8610277376.0000\n",
      "Epoch 935/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7676370944.0000 - val_loss: 9638071296.0000\n",
      "Epoch 936/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 6ms/step - loss: 7766203392.0000 - val_loss: 8703625216.0000\n",
      "Epoch 937/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7608070144.0000 - val_loss: 8529613824.0000\n",
      "Epoch 938/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7759546880.0000 - val_loss: 8348372992.0000\n",
      "Epoch 939/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7799174656.0000 - val_loss: 9595943936.0000\n",
      "Epoch 940/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7665447424.0000 - val_loss: 8671412224.0000\n",
      "Epoch 941/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7666737152.0000 - val_loss: 8500179968.0000\n",
      "Epoch 942/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7792052736.0000 - val_loss: 8415014400.0000\n",
      "Epoch 943/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7666214912.0000 - val_loss: 8397420032.0000\n",
      "Epoch 944/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7577580032.0000 - val_loss: 8836533248.0000\n",
      "Epoch 945/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7802519552.0000 - val_loss: 9192802304.0000\n",
      "Epoch 946/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7558262272.0000 - val_loss: 8428134912.0000\n",
      "Epoch 947/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7688175616.0000 - val_loss: 8354172416.0000\n",
      "Epoch 948/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7653334528.0000 - val_loss: 8309740544.0000\n",
      "Epoch 949/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7748345856.0000 - val_loss: 8946716672.0000\n",
      "Epoch 950/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7800545792.0000 - val_loss: 8669042688.0000\n",
      "Epoch 951/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7881369600.0000 - val_loss: 8555257856.0000\n",
      "Epoch 952/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7614583808.0000 - val_loss: 8535371776.0000\n",
      "Epoch 953/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7868887040.0000 - val_loss: 8656650240.0000\n",
      "Epoch 954/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7684289024.0000 - val_loss: 8350373376.0000\n",
      "Epoch 955/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7815922176.0000 - val_loss: 8403655168.0000\n",
      "Epoch 956/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7656243712.0000 - val_loss: 8759728128.0000\n",
      "Epoch 957/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7870543872.0000 - val_loss: 9805249536.0000\n",
      "Epoch 958/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7646380032.0000 - val_loss: 9002248192.0000\n",
      "Epoch 959/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7620624384.0000 - val_loss: 8429453312.0000\n",
      "Epoch 960/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7552274432.0000 - val_loss: 8390047232.0000\n",
      "Epoch 961/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7631302656.0000 - val_loss: 8327070208.0000\n",
      "Epoch 962/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7587791872.0000 - val_loss: 8307057152.0000\n",
      "Epoch 963/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7702571008.0000 - val_loss: 8740531200.0000\n",
      "Epoch 964/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7583267840.0000 - val_loss: 8881139712.0000\n",
      "Epoch 965/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7663501824.0000 - val_loss: 8341679104.0000\n",
      "Epoch 966/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7755601920.0000 - val_loss: 8546494976.0000\n",
      "Epoch 967/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7731677184.0000 - val_loss: 9039990784.0000\n",
      "Epoch 968/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7616956928.0000 - val_loss: 8517692928.0000\n",
      "Epoch 969/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7641752064.0000 - val_loss: 8303903744.0000\n",
      "Epoch 970/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7701056000.0000 - val_loss: 8341228032.0000\n",
      "Epoch 971/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7959309824.0000 - val_loss: 8581866496.0000\n",
      "Epoch 972/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7765706240.0000 - val_loss: 9395929088.0000\n",
      "Epoch 973/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7925545984.0000 - val_loss: 8324688896.0000\n",
      "Epoch 974/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7629168128.0000 - val_loss: 8752552960.0000\n",
      "Epoch 975/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7746839552.0000 - val_loss: 8371067904.0000\n",
      "Epoch 976/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7732831744.0000 - val_loss: 8772537344.0000\n",
      "Epoch 977/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7580384768.0000 - val_loss: 8427954176.0000\n",
      "Epoch 978/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7605070336.0000 - val_loss: 8831364096.0000\n",
      "Epoch 979/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7821778944.0000 - val_loss: 8505874432.0000\n",
      "Epoch 980/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7594300416.0000 - val_loss: 8322198528.0000\n",
      "Epoch 981/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7778251264.0000 - val_loss: 8518922752.0000\n",
      "Epoch 982/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7679576064.0000 - val_loss: 8327910912.0000\n",
      "Epoch 983/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7691483136.0000 - val_loss: 8956958720.0000\n",
      "Epoch 984/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7643265024.0000 - val_loss: 8310277120.0000\n",
      "Epoch 985/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7561368064.0000 - val_loss: 8325805056.0000\n",
      "Epoch 986/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7744105984.0000 - val_loss: 9749126144.0000\n",
      "Epoch 987/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7603740672.0000 - val_loss: 8373370880.0000\n",
      "Epoch 988/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7715301888.0000 - val_loss: 8402992640.0000\n",
      "Epoch 989/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7683289088.0000 - val_loss: 8549644288.0000\n",
      "Epoch 990/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7582505984.0000 - val_loss: 8285208576.0000\n",
      "Epoch 991/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7711931392.0000 - val_loss: 8690543616.0000\n",
      "Epoch 992/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7910713344.0000 - val_loss: 8463006720.0000\n",
      "Epoch 993/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7589970432.0000 - val_loss: 8939453440.0000\n",
      "Epoch 994/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7752080384.0000 - val_loss: 8777367552.0000\n",
      "Epoch 995/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7705594368.0000 - val_loss: 8332737024.0000\n",
      "Epoch 996/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7598701056.0000 - val_loss: 8352889856.0000\n",
      "Epoch 997/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7731743232.0000 - val_loss: 8300688384.0000\n",
      "Epoch 998/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7580148224.0000 - val_loss: 8448032768.0000\n",
      "Epoch 999/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7670705664.0000 - val_loss: 8481405952.0000\n",
      "Epoch 1000/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7583724032.0000 - val_loss: 8341139456.0000\n",
      "Epoch 1001/1500\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 7647159296.0000 - val_loss: 8399255040.0000\n",
      "Epoch 1002/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7534646784.0000 - val_loss: 8293369344.0000\n",
      "Epoch 1003/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7738156544.0000 - val_loss: 8516622848.0000\n",
      "Epoch 1004/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7990386688.0000 - val_loss: 8973284352.0000\n",
      "Epoch 1005/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7665584128.0000 - val_loss: 8707001344.0000\n",
      "Epoch 1006/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7655311360.0000 - val_loss: 8760141824.0000\n",
      "Epoch 1007/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7563511296.0000 - val_loss: 8297026048.0000\n",
      "Epoch 1008/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7586736128.0000 - val_loss: 8392511488.0000\n",
      "Epoch 1009/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7624784896.0000 - val_loss: 8357411328.0000\n",
      "Epoch 1010/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7570234880.0000 - val_loss: 8289285632.0000\n",
      "Epoch 1011/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7820165120.0000 - val_loss: 9008687104.0000\n",
      "Epoch 1012/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7814054400.0000 - val_loss: 8328210944.0000\n",
      "Epoch 1013/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7585795072.0000 - val_loss: 8349049344.0000\n",
      "Epoch 1014/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7653110784.0000 - val_loss: 9587073024.0000\n",
      "Epoch 1015/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7673371136.0000 - val_loss: 9047254016.0000\n",
      "Epoch 1016/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7607809536.0000 - val_loss: 8810464256.0000\n",
      "Epoch 1017/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7552245248.0000 - val_loss: 8707986432.0000\n",
      "Epoch 1018/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7716809216.0000 - val_loss: 8931253248.0000\n",
      "Epoch 1019/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7606667776.0000 - val_loss: 8493337600.0000\n",
      "Epoch 1020/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7745042432.0000 - val_loss: 8282151936.0000\n",
      "Epoch 1021/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7535928832.0000 - val_loss: 8802538496.0000\n",
      "Epoch 1022/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7540960256.0000 - val_loss: 8636568576.0000\n",
      "Epoch 1023/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7551398400.0000 - val_loss: 8586639872.0000\n",
      "Epoch 1024/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7591356928.0000 - val_loss: 8338851328.0000\n",
      "Epoch 1025/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7717643264.0000 - val_loss: 8804559872.0000\n",
      "Epoch 1026/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7607472640.0000 - val_loss: 8316073472.0000\n",
      "Epoch 1027/1500\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 7615309312.0000 - val_loss: 8513778176.0000\n",
      "Epoch 1028/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7832067584.0000 - val_loss: 8526297600.0000\n",
      "Epoch 1029/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7591533056.0000 - val_loss: 8786696192.0000\n",
      "Epoch 1030/1500\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 7535696896.0000 - val_loss: 8442929664.0000\n",
      "Epoch 1031/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7572295680.0000 - val_loss: 8250886656.0000\n",
      "Epoch 1032/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7748769280.0000 - val_loss: 8412242432.0000\n",
      "Epoch 1033/1500\n",
      "119/119 [==============================] - 2s 15ms/step - loss: 7576817152.0000 - val_loss: 8429308416.0000\n",
      "Epoch 1034/1500\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 7678090752.0000 - val_loss: 8936727552.0000\n",
      "Epoch 1035/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7762951680.0000 - val_loss: 8255913984.0000\n",
      "Epoch 1036/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7510333952.0000 - val_loss: 8313010688.0000\n",
      "Epoch 1037/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7491904000.0000 - val_loss: 8278142976.0000\n",
      "Epoch 1038/1500\n",
      "119/119 [==============================] - 2s 15ms/step - loss: 7696241152.0000 - val_loss: 8401735168.0000\n",
      "Epoch 1039/1500\n",
      "119/119 [==============================] - 2s 16ms/step - loss: 7552154112.0000 - val_loss: 8321600512.0000\n",
      "Epoch 1040/1500\n",
      "119/119 [==============================] - 2s 15ms/step - loss: 7549107200.0000 - val_loss: 8276597248.0000\n",
      "Epoch 1041/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7525772800.0000 - val_loss: 8305135104.0000\n",
      "Epoch 1042/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7535665152.0000 - val_loss: 8390141952.0000\n",
      "Epoch 1043/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7807463424.0000 - val_loss: 9005003776.0000\n",
      "Epoch 1044/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7559326720.0000 - val_loss: 8302648320.0000\n",
      "Epoch 1045/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7572025344.0000 - val_loss: 8805850112.0000\n",
      "Epoch 1046/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7826992128.0000 - val_loss: 8301564416.0000\n",
      "Epoch 1047/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7560027648.0000 - val_loss: 8352283136.0000\n",
      "Epoch 1048/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7630725632.0000 - val_loss: 8287154176.0000\n",
      "Epoch 1049/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7613510656.0000 - val_loss: 8475749376.0000\n",
      "Epoch 1050/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7594010112.0000 - val_loss: 8520836608.0000\n",
      "Epoch 1051/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7595090944.0000 - val_loss: 8256109568.0000\n",
      "Epoch 1052/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7617447936.0000 - val_loss: 8455863296.0000\n",
      "Epoch 1053/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7570487808.0000 - val_loss: 8259041792.0000\n",
      "Epoch 1054/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7587376640.0000 - val_loss: 9606523904.0000\n",
      "Epoch 1055/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7708972032.0000 - val_loss: 8273658368.0000\n",
      "Epoch 1056/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7550353408.0000 - val_loss: 8851368960.0000\n",
      "Epoch 1057/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7701752832.0000 - val_loss: 8546409472.0000\n",
      "Epoch 1058/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7753573888.0000 - val_loss: 8358855680.0000\n",
      "Epoch 1059/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7644338688.0000 - val_loss: 8458148352.0000\n",
      "Epoch 1060/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7515993088.0000 - val_loss: 9165205504.0000\n",
      "Epoch 1061/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7542906880.0000 - val_loss: 8348387328.0000\n",
      "Epoch 1062/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7680241152.0000 - val_loss: 8580409856.0000\n",
      "Epoch 1063/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7913940480.0000 - val_loss: 8279772160.0000\n",
      "Epoch 1064/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7629367296.0000 - val_loss: 8239358976.0000\n",
      "Epoch 1065/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7546190336.0000 - val_loss: 8446136320.0000\n",
      "Epoch 1066/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7521461248.0000 - val_loss: 8407808512.0000\n",
      "Epoch 1067/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7424544768.0000 - val_loss: 8236893184.0000\n",
      "Epoch 1068/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7554223104.0000 - val_loss: 8257601024.0000\n",
      "Epoch 1069/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 7ms/step - loss: 7578614784.0000 - val_loss: 9786249216.0000\n",
      "Epoch 1070/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7684152320.0000 - val_loss: 8315180032.0000\n",
      "Epoch 1071/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7467642368.0000 - val_loss: 8315063808.0000\n",
      "Epoch 1072/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7597800448.0000 - val_loss: 8308429312.0000\n",
      "Epoch 1073/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7605303808.0000 - val_loss: 8267897856.0000\n",
      "Epoch 1074/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7837523968.0000 - val_loss: 8874217472.0000\n",
      "Epoch 1075/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7606099968.0000 - val_loss: 8402325504.0000\n",
      "Epoch 1076/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7529147392.0000 - val_loss: 8239598080.0000\n",
      "Epoch 1077/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7442381824.0000 - val_loss: 8411937280.0000\n",
      "Epoch 1078/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7668889600.0000 - val_loss: 8805163008.0000\n",
      "Epoch 1079/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7466729472.0000 - val_loss: 8356518912.0000\n",
      "Epoch 1080/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7558216704.0000 - val_loss: 8245203968.0000\n",
      "Epoch 1081/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7649912320.0000 - val_loss: 8841261056.0000\n",
      "Epoch 1082/1500\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 7501756416.0000 - val_loss: 9597595648.0000\n",
      "Epoch 1083/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7865193472.0000 - val_loss: 8553325568.0000\n",
      "Epoch 1084/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7450632192.0000 - val_loss: 8290732544.0000\n",
      "Epoch 1085/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7503648768.0000 - val_loss: 8252439552.0000\n",
      "Epoch 1086/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7503816192.0000 - val_loss: 8306690048.0000\n",
      "Epoch 1087/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7470572544.0000 - val_loss: 8248971776.0000\n",
      "Epoch 1088/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7615841792.0000 - val_loss: 8284053504.0000\n",
      "Epoch 1089/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7484881920.0000 - val_loss: 8620954624.0000\n",
      "Epoch 1090/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7629858816.0000 - val_loss: 8273448960.0000\n",
      "Epoch 1091/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7644003328.0000 - val_loss: 8328758272.0000\n",
      "Epoch 1092/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7465561600.0000 - val_loss: 8874405888.0000\n",
      "Epoch 1093/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7579819520.0000 - val_loss: 8296809984.0000\n",
      "Epoch 1094/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7519004672.0000 - val_loss: 8273590272.0000\n",
      "Epoch 1095/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7431383040.0000 - val_loss: 8418381824.0000\n",
      "Epoch 1096/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7545089536.0000 - val_loss: 8455697408.0000\n",
      "Epoch 1097/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7479783936.0000 - val_loss: 8236803072.0000\n",
      "Epoch 1098/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7470186496.0000 - val_loss: 9163794432.0000\n",
      "Epoch 1099/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7579399680.0000 - val_loss: 8256130560.0000\n",
      "Epoch 1100/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7559347712.0000 - val_loss: 8836271104.0000\n",
      "Epoch 1101/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7459826688.0000 - val_loss: 8287947776.0000\n",
      "Epoch 1102/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7424495616.0000 - val_loss: 8315060224.0000\n",
      "Epoch 1103/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7571159552.0000 - val_loss: 8435028480.0000\n",
      "Epoch 1104/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7453807104.0000 - val_loss: 8430173696.0000\n",
      "Epoch 1105/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7524488192.0000 - val_loss: 8293767168.0000\n",
      "Epoch 1106/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7571801600.0000 - val_loss: 8581766656.0000\n",
      "Epoch 1107/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7636325888.0000 - val_loss: 8303284736.0000\n",
      "Epoch 1108/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7521595392.0000 - val_loss: 9023113216.0000\n",
      "Epoch 1109/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7630540288.0000 - val_loss: 8525510144.0000\n",
      "Epoch 1110/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7500849152.0000 - val_loss: 9457833984.0000\n",
      "Epoch 1111/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7853258240.0000 - val_loss: 8545652224.0000\n",
      "Epoch 1112/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7396105216.0000 - val_loss: 8507102720.0000\n",
      "Epoch 1113/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7462033408.0000 - val_loss: 8437722112.0000\n",
      "Epoch 1114/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7476094464.0000 - val_loss: 8237316608.0000\n",
      "Epoch 1115/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7477735424.0000 - val_loss: 8796960768.0000\n",
      "Epoch 1116/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7641339904.0000 - val_loss: 8252177408.0000\n",
      "Epoch 1117/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7548217344.0000 - val_loss: 8526625280.0000\n",
      "Epoch 1118/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7511166464.0000 - val_loss: 8309582848.0000\n",
      "Epoch 1119/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7441296384.0000 - val_loss: 8323211264.0000\n",
      "Epoch 1120/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7755636736.0000 - val_loss: 8391909376.0000\n",
      "Epoch 1121/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7636746752.0000 - val_loss: 8706883584.0000\n",
      "Epoch 1122/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7412134912.0000 - val_loss: 8349445632.0000\n",
      "Epoch 1123/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7447972864.0000 - val_loss: 8343649280.0000\n",
      "Epoch 1124/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7482130944.0000 - val_loss: 8223833088.0000\n",
      "Epoch 1125/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7587901440.0000 - val_loss: 9950749696.0000\n",
      "Epoch 1126/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7624041472.0000 - val_loss: 8339075072.0000\n",
      "Epoch 1127/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7540481024.0000 - val_loss: 8199617536.0000\n",
      "Epoch 1128/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7740316672.0000 - val_loss: 8631215104.0000\n",
      "Epoch 1129/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7445901312.0000 - val_loss: 8315040256.0000\n",
      "Epoch 1130/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7560264704.0000 - val_loss: 8280694784.0000\n",
      "Epoch 1131/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7414984704.0000 - val_loss: 8285000704.0000\n",
      "Epoch 1132/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7633931776.0000 - val_loss: 8225280000.0000\n",
      "Epoch 1133/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7762950144.0000 - val_loss: 8330906112.0000\n",
      "Epoch 1134/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7477963264.0000 - val_loss: 10111003648.0000\n",
      "Epoch 1135/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7557999616.0000 - val_loss: 8393164288.0000\n",
      "Epoch 1136/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7627948544.0000 - val_loss: 8438131200.0000\n",
      "Epoch 1137/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7440189440.0000 - val_loss: 8324368384.0000\n",
      "Epoch 1138/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7616643584.0000 - val_loss: 8232603648.0000\n",
      "Epoch 1139/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7587576320.0000 - val_loss: 9141061632.0000\n",
      "Epoch 1140/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7428990464.0000 - val_loss: 8194987008.0000\n",
      "Epoch 1141/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7468338688.0000 - val_loss: 8218132480.0000\n",
      "Epoch 1142/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7437497344.0000 - val_loss: 8431593472.0000\n",
      "Epoch 1143/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7469319680.0000 - val_loss: 8183086592.0000\n",
      "Epoch 1144/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7466378240.0000 - val_loss: 8488932352.0000\n",
      "Epoch 1145/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7551791104.0000 - val_loss: 8346422784.0000\n",
      "Epoch 1146/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7549164032.0000 - val_loss: 9420882944.0000\n",
      "Epoch 1147/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7616230400.0000 - val_loss: 8526520832.0000\n",
      "Epoch 1148/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7406790144.0000 - val_loss: 8297697280.0000\n",
      "Epoch 1149/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7467910656.0000 - val_loss: 8201559552.0000\n",
      "Epoch 1150/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7410638848.0000 - val_loss: 8238161920.0000\n",
      "Epoch 1151/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7493942272.0000 - val_loss: 8730506240.0000\n",
      "Epoch 1152/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7576292352.0000 - val_loss: 8296680448.0000\n",
      "Epoch 1153/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7704276992.0000 - val_loss: 8226016256.0000\n",
      "Epoch 1154/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7543420416.0000 - val_loss: 8271289856.0000\n",
      "Epoch 1155/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7628034048.0000 - val_loss: 8254703616.0000\n",
      "Epoch 1156/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7496628736.0000 - val_loss: 8936832000.0000\n",
      "Epoch 1157/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7440770048.0000 - val_loss: 8254235136.0000\n",
      "Epoch 1158/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7494793216.0000 - val_loss: 8455441920.0000\n",
      "Epoch 1159/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7409494528.0000 - val_loss: 8494917632.0000\n",
      "Epoch 1160/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7590147584.0000 - val_loss: 8486558208.0000\n",
      "Epoch 1161/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7480722944.0000 - val_loss: 8269328896.0000\n",
      "Epoch 1162/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7366472192.0000 - val_loss: 8408120320.0000\n",
      "Epoch 1163/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7639953408.0000 - val_loss: 8295932928.0000\n",
      "Epoch 1164/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7400227328.0000 - val_loss: 8164387328.0000\n",
      "Epoch 1165/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7479538176.0000 - val_loss: 8496598016.0000\n",
      "Epoch 1166/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7546409984.0000 - val_loss: 8169652224.0000\n",
      "Epoch 1167/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7388085248.0000 - val_loss: 8347188736.0000\n",
      "Epoch 1168/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7546166784.0000 - val_loss: 8277411328.0000\n",
      "Epoch 1169/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7457918976.0000 - val_loss: 8215300608.0000\n",
      "Epoch 1170/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7491976192.0000 - val_loss: 8170869760.0000\n",
      "Epoch 1171/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7529248256.0000 - val_loss: 8281450496.0000\n",
      "Epoch 1172/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7420452864.0000 - val_loss: 8827585536.0000\n",
      "Epoch 1173/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7407360512.0000 - val_loss: 8155097600.0000\n",
      "Epoch 1174/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7538898432.0000 - val_loss: 9046798336.0000\n",
      "Epoch 1175/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7457822208.0000 - val_loss: 8248103936.0000\n",
      "Epoch 1176/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7458561536.0000 - val_loss: 8197109760.0000\n",
      "Epoch 1177/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7488122368.0000 - val_loss: 8178358272.0000\n",
      "Epoch 1178/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7407729152.0000 - val_loss: 9588452352.0000\n",
      "Epoch 1179/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7537598976.0000 - val_loss: 8172189696.0000\n",
      "Epoch 1180/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7551876608.0000 - val_loss: 8167803392.0000\n",
      "Epoch 1181/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7366009856.0000 - val_loss: 8154110464.0000\n",
      "Epoch 1182/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7628422144.0000 - val_loss: 8308478464.0000\n",
      "Epoch 1183/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7673549312.0000 - val_loss: 8481292288.0000\n",
      "Epoch 1184/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7443649024.0000 - val_loss: 8388106752.0000\n",
      "Epoch 1185/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7433470976.0000 - val_loss: 8238311936.0000\n",
      "Epoch 1186/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7403653120.0000 - val_loss: 8732024832.0000\n",
      "Epoch 1187/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7393915904.0000 - val_loss: 8379695616.0000\n",
      "Epoch 1188/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7468820992.0000 - val_loss: 8263055360.0000\n",
      "Epoch 1189/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7758184960.0000 - val_loss: 8263661568.0000\n",
      "Epoch 1190/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7367788032.0000 - val_loss: 8354179584.0000\n",
      "Epoch 1191/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7606302720.0000 - val_loss: 8525912576.0000\n",
      "Epoch 1192/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7390033408.0000 - val_loss: 8265794560.0000\n",
      "Epoch 1193/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7556264448.0000 - val_loss: 8674893824.0000\n",
      "Epoch 1194/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7658136576.0000 - val_loss: 8308733952.0000\n",
      "Epoch 1195/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7480157184.0000 - val_loss: 8200908800.0000\n",
      "Epoch 1196/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7640866816.0000 - val_loss: 8530605056.0000\n",
      "Epoch 1197/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7409684992.0000 - val_loss: 8241697792.0000\n",
      "Epoch 1198/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7334716928.0000 - val_loss: 8755346432.0000\n",
      "Epoch 1199/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7480463872.0000 - val_loss: 8161723392.0000\n",
      "Epoch 1200/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7571296256.0000 - val_loss: 8277837824.0000\n",
      "Epoch 1201/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7432325120.0000 - val_loss: 8163980800.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1202/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7562034688.0000 - val_loss: 8244305920.0000\n",
      "Epoch 1203/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7405676544.0000 - val_loss: 8301094912.0000\n",
      "Epoch 1204/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7418256896.0000 - val_loss: 8371359744.0000\n",
      "Epoch 1205/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7692990464.0000 - val_loss: 8248173056.0000\n",
      "Epoch 1206/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7589160448.0000 - val_loss: 8546394624.0000\n",
      "Epoch 1207/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7378468352.0000 - val_loss: 8617084928.0000\n",
      "Epoch 1208/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7429481984.0000 - val_loss: 8424367616.0000\n",
      "Epoch 1209/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7436369408.0000 - val_loss: 8236434432.0000\n",
      "Epoch 1210/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7423993856.0000 - val_loss: 8865521664.0000\n",
      "Epoch 1211/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7602014720.0000 - val_loss: 8340746240.0000\n",
      "Epoch 1212/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7360784384.0000 - val_loss: 8205628928.0000\n",
      "Epoch 1213/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7402899968.0000 - val_loss: 8576259072.0000\n",
      "Epoch 1214/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7336855552.0000 - val_loss: 8171358720.0000\n",
      "Epoch 1215/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7392987648.0000 - val_loss: 8514523136.0000\n",
      "Epoch 1216/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7346679296.0000 - val_loss: 8269857280.0000\n",
      "Epoch 1217/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7421835264.0000 - val_loss: 8145369088.0000\n",
      "Epoch 1218/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7368990720.0000 - val_loss: 8431255552.0000\n",
      "Epoch 1219/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7491266560.0000 - val_loss: 8327866368.0000\n",
      "Epoch 1220/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7336561152.0000 - val_loss: 8293820928.0000\n",
      "Epoch 1221/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7368727040.0000 - val_loss: 8520644096.0000\n",
      "Epoch 1222/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7543398400.0000 - val_loss: 8818397184.0000\n",
      "Epoch 1223/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7356879360.0000 - val_loss: 8570662400.0000\n",
      "Epoch 1224/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7392867840.0000 - val_loss: 8247373824.0000\n",
      "Epoch 1225/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7338806272.0000 - val_loss: 8879655936.0000\n",
      "Epoch 1226/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7523616256.0000 - val_loss: 8505365504.0000\n",
      "Epoch 1227/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7522296832.0000 - val_loss: 8282381824.0000\n",
      "Epoch 1228/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7427445760.0000 - val_loss: 8361637888.0000\n",
      "Epoch 1229/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7426770432.0000 - val_loss: 8618002432.0000\n",
      "Epoch 1230/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7365725696.0000 - val_loss: 8220054528.0000\n",
      "Epoch 1231/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7421941248.0000 - val_loss: 8680455168.0000\n",
      "Epoch 1232/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7433102848.0000 - val_loss: 8165730304.0000\n",
      "Epoch 1233/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7314744320.0000 - val_loss: 8166236672.0000\n",
      "Epoch 1234/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7562438144.0000 - val_loss: 8400189440.0000\n",
      "Epoch 1235/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7405217280.0000 - val_loss: 8267550720.0000\n",
      "Epoch 1236/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7423384064.0000 - val_loss: 9606946816.0000\n",
      "Epoch 1237/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7480324608.0000 - val_loss: 9095358464.0000\n",
      "Epoch 1238/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7531809792.0000 - val_loss: 8442273280.0000\n",
      "Epoch 1239/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7397873152.0000 - val_loss: 8229657088.0000\n",
      "Epoch 1240/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7485716992.0000 - val_loss: 8435026432.0000\n",
      "Epoch 1241/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7572847616.0000 - val_loss: 8258964480.0000\n",
      "Epoch 1242/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7403467776.0000 - val_loss: 8334749696.0000\n",
      "Epoch 1243/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7406795776.0000 - val_loss: 8863488000.0000\n",
      "Epoch 1244/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7382377984.0000 - val_loss: 8309753344.0000\n",
      "Epoch 1245/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7290875392.0000 - val_loss: 8126658048.0000\n",
      "Epoch 1246/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7562563584.0000 - val_loss: 8294192640.0000\n",
      "Epoch 1247/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7385579008.0000 - val_loss: 8801154048.0000\n",
      "Epoch 1248/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7432033792.0000 - val_loss: 8170182144.0000\n",
      "Epoch 1249/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7331553280.0000 - val_loss: 8286394368.0000\n",
      "Epoch 1250/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7457181696.0000 - val_loss: 8414136320.0000\n",
      "Epoch 1251/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7427804160.0000 - val_loss: 8195582976.0000\n",
      "Epoch 1252/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7275063296.0000 - val_loss: 9094146048.0000\n",
      "Epoch 1253/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7630836736.0000 - val_loss: 8847954944.0000\n",
      "Epoch 1254/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7453969920.0000 - val_loss: 8414057472.0000\n",
      "Epoch 1255/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7361243648.0000 - val_loss: 8379608576.0000\n",
      "Epoch 1256/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7361150464.0000 - val_loss: 8156273152.0000\n",
      "Epoch 1257/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7321082880.0000 - val_loss: 8500335104.0000\n",
      "Epoch 1258/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7361892864.0000 - val_loss: 8280202752.0000\n",
      "Epoch 1259/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7499930624.0000 - val_loss: 8379967488.0000\n",
      "Epoch 1260/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7342189568.0000 - val_loss: 8370149376.0000\n",
      "Epoch 1261/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7343230976.0000 - val_loss: 8538182656.0000\n",
      "Epoch 1262/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7552475136.0000 - val_loss: 8458350592.0000\n",
      "Epoch 1263/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7410344960.0000 - val_loss: 8568252416.0000\n",
      "Epoch 1264/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7708405248.0000 - val_loss: 10543756288.0000\n",
      "Epoch 1265/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7611196928.0000 - val_loss: 8139130880.0000\n",
      "Epoch 1266/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7297640960.0000 - val_loss: 8248666112.0000\n",
      "Epoch 1267/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7378641408.0000 - val_loss: 8372590592.0000\n",
      "Epoch 1268/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7696203776.0000 - val_loss: 8223825920.0000\n",
      "Epoch 1269/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7364022272.0000 - val_loss: 8713157632.0000\n",
      "Epoch 1270/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7347782144.0000 - val_loss: 8225512448.0000\n",
      "Epoch 1271/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7332776448.0000 - val_loss: 8233692672.0000\n",
      "Epoch 1272/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7300834816.0000 - val_loss: 8297725952.0000\n",
      "Epoch 1273/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7359991296.0000 - val_loss: 9055383552.0000\n",
      "Epoch 1274/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7391612928.0000 - val_loss: 8324789248.0000\n",
      "Epoch 1275/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7393049600.0000 - val_loss: 8154126336.0000\n",
      "Epoch 1276/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7524181504.0000 - val_loss: 9553822720.0000\n",
      "Epoch 1277/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7449967104.0000 - val_loss: 8961039360.0000\n",
      "Epoch 1278/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7438442496.0000 - val_loss: 8175104000.0000\n",
      "Epoch 1279/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7418680832.0000 - val_loss: 8385472000.0000\n",
      "Epoch 1280/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7437620736.0000 - val_loss: 9138923520.0000\n",
      "Epoch 1281/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7799836672.0000 - val_loss: 9410397184.0000\n",
      "Epoch 1282/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7289824768.0000 - val_loss: 8329074176.0000\n",
      "Epoch 1283/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7430303744.0000 - val_loss: 8333371392.0000\n",
      "Epoch 1284/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7366658048.0000 - val_loss: 8239704064.0000\n",
      "Epoch 1285/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7507023360.0000 - val_loss: 8343778816.0000\n",
      "Epoch 1286/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7479561216.0000 - val_loss: 10080758784.0000\n",
      "Epoch 1287/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7515920384.0000 - val_loss: 8124127232.0000\n",
      "Epoch 1288/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7414349824.0000 - val_loss: 8175821312.0000\n",
      "Epoch 1289/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7314552832.0000 - val_loss: 8228141568.0000\n",
      "Epoch 1290/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7375162368.0000 - val_loss: 8269192192.0000\n",
      "Epoch 1291/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7419014144.0000 - val_loss: 8529417728.0000\n",
      "Epoch 1292/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7694351360.0000 - val_loss: 8308340224.0000\n",
      "Epoch 1293/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7316976640.0000 - val_loss: 8479701504.0000\n",
      "Epoch 1294/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7620403712.0000 - val_loss: 8171704832.0000\n",
      "Epoch 1295/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7671277568.0000 - val_loss: 8244633088.0000\n",
      "Epoch 1296/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7274619392.0000 - val_loss: 8218405888.0000\n",
      "Epoch 1297/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7414477824.0000 - val_loss: 8396126208.0000\n",
      "Epoch 1298/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7338423296.0000 - val_loss: 8259131392.0000\n",
      "Epoch 1299/1500\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 7481324032.0000 - val_loss: 8351249920.0000\n",
      "Epoch 1300/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7268492800.0000 - val_loss: 8634081280.0000\n",
      "Epoch 1301/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7505260544.0000 - val_loss: 8294538240.0000\n",
      "Epoch 1302/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7409433088.0000 - val_loss: 8204012544.0000\n",
      "Epoch 1303/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7282051584.0000 - val_loss: 8269971456.0000\n",
      "Epoch 1304/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7394650112.0000 - val_loss: 8185430016.0000\n",
      "Epoch 1305/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7371932160.0000 - val_loss: 8172962304.0000\n",
      "Epoch 1306/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7290555392.0000 - val_loss: 8427599872.0000\n",
      "Epoch 1307/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7420620800.0000 - val_loss: 8179082240.0000\n",
      "Epoch 1308/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7637343744.0000 - val_loss: 10051476480.0000\n",
      "Epoch 1309/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7726750720.0000 - val_loss: 8237905408.0000\n",
      "Epoch 1310/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7321768448.0000 - val_loss: 8444652544.0000\n",
      "Epoch 1311/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7322913280.0000 - val_loss: 8479388160.0000\n",
      "Epoch 1312/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7381834240.0000 - val_loss: 8116164608.0000\n",
      "Epoch 1313/1500\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 7458792960.0000 - val_loss: 9350013952.0000\n",
      "Epoch 1314/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7540055552.0000 - val_loss: 9352937472.0000\n",
      "Epoch 1315/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7508335104.0000 - val_loss: 8157096960.0000\n",
      "Epoch 1316/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7433242112.0000 - val_loss: 8266576384.0000\n",
      "Epoch 1317/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7607346176.0000 - val_loss: 8304220160.0000\n",
      "Epoch 1318/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7260587008.0000 - val_loss: 9434141696.0000\n",
      "Epoch 1319/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7359100928.0000 - val_loss: 8434107904.0000\n",
      "Epoch 1320/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7229322752.0000 - val_loss: 8197396992.0000\n",
      "Epoch 1321/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7295826944.0000 - val_loss: 8195456512.0000\n",
      "Epoch 1322/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7317240320.0000 - val_loss: 8140918272.0000\n",
      "Epoch 1323/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7355942400.0000 - val_loss: 8263663616.0000\n",
      "Epoch 1324/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7392162304.0000 - val_loss: 9779043328.0000\n",
      "Epoch 1325/1500\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 7380936704.0000 - val_loss: 8198832128.0000\n",
      "Epoch 1326/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7460429824.0000 - val_loss: 8177961984.0000\n",
      "Epoch 1327/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7414769664.0000 - val_loss: 8195758080.0000\n",
      "Epoch 1328/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7353996288.0000 - val_loss: 8151670272.0000\n",
      "Epoch 1329/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7380628480.0000 - val_loss: 9078862848.0000\n",
      "Epoch 1330/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7465499136.0000 - val_loss: 8504037376.0000\n",
      "Epoch 1331/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7463838720.0000 - val_loss: 10688335872.0000\n",
      "Epoch 1332/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7363217920.0000 - val_loss: 8290386944.0000\n",
      "Epoch 1333/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7385333760.0000 - val_loss: 8089523712.0000\n",
      "Epoch 1334/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 7ms/step - loss: 7421779968.0000 - val_loss: 8283672576.0000\n",
      "Epoch 1335/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7312280576.0000 - val_loss: 8157395456.0000\n",
      "Epoch 1336/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7473050624.0000 - val_loss: 8142536704.0000\n",
      "Epoch 1337/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7345882624.0000 - val_loss: 8177019904.0000\n",
      "Epoch 1338/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7294067712.0000 - val_loss: 8167130112.0000\n",
      "Epoch 1339/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7244890624.0000 - val_loss: 8109908992.0000\n",
      "Epoch 1340/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7847923200.0000 - val_loss: 8260147200.0000\n",
      "Epoch 1341/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7451342848.0000 - val_loss: 8293768704.0000\n",
      "Epoch 1342/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7314433536.0000 - val_loss: 8678351872.0000\n",
      "Epoch 1343/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7310988288.0000 - val_loss: 8574801920.0000\n",
      "Epoch 1344/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7326055936.0000 - val_loss: 9431051264.0000\n",
      "Epoch 1345/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7413245952.0000 - val_loss: 8129891328.0000\n",
      "Epoch 1346/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7504077312.0000 - val_loss: 8402338304.0000\n",
      "Epoch 1347/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7283796992.0000 - val_loss: 8085320192.0000\n",
      "Epoch 1348/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7470660096.0000 - val_loss: 8253638656.0000\n",
      "Epoch 1349/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7285220352.0000 - val_loss: 9086180352.0000\n",
      "Epoch 1350/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7433196544.0000 - val_loss: 8282784256.0000\n",
      "Epoch 1351/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7515023872.0000 - val_loss: 8945553408.0000\n",
      "Epoch 1352/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7381602816.0000 - val_loss: 8382495232.0000\n",
      "Epoch 1353/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7698435072.0000 - val_loss: 8762427392.0000\n",
      "Epoch 1354/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7246714880.0000 - val_loss: 8112563712.0000\n",
      "Epoch 1355/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7234084864.0000 - val_loss: 8175404544.0000\n",
      "Epoch 1356/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7469407744.0000 - val_loss: 9740120064.0000\n",
      "Epoch 1357/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7372265472.0000 - val_loss: 8224898560.0000\n",
      "Epoch 1358/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7300894208.0000 - val_loss: 8146514432.0000\n",
      "Epoch 1359/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7469018112.0000 - val_loss: 8820406272.0000\n",
      "Epoch 1360/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7414502912.0000 - val_loss: 8400194048.0000\n",
      "Epoch 1361/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7344363520.0000 - val_loss: 9420187648.0000\n",
      "Epoch 1362/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7589790720.0000 - val_loss: 8467950080.0000\n",
      "Epoch 1363/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7408589824.0000 - val_loss: 8299624960.0000\n",
      "Epoch 1364/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7435576320.0000 - val_loss: 10177651712.0000\n",
      "Epoch 1365/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7389200384.0000 - val_loss: 8518953984.0000\n",
      "Epoch 1366/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7295109632.0000 - val_loss: 8247604736.0000\n",
      "Epoch 1367/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7342033920.0000 - val_loss: 8228765184.0000\n",
      "Epoch 1368/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7213827584.0000 - val_loss: 8375759872.0000\n",
      "Epoch 1369/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7458503168.0000 - val_loss: 8815207424.0000\n",
      "Epoch 1370/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7393376768.0000 - val_loss: 8441433088.0000\n",
      "Epoch 1371/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7296201216.0000 - val_loss: 8424303104.0000\n",
      "Epoch 1372/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7300820480.0000 - val_loss: 8144520704.0000\n",
      "Epoch 1373/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7269388288.0000 - val_loss: 8246106112.0000\n",
      "Epoch 1374/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7487711232.0000 - val_loss: 8184313344.0000\n",
      "Epoch 1375/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7346815488.0000 - val_loss: 8445611520.0000\n",
      "Epoch 1376/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7241896448.0000 - val_loss: 8191252480.0000\n",
      "Epoch 1377/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7242475008.0000 - val_loss: 8318993408.0000\n",
      "Epoch 1378/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7436073984.0000 - val_loss: 8711685120.0000\n",
      "Epoch 1379/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7598930944.0000 - val_loss: 8186085888.0000\n",
      "Epoch 1380/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7528817152.0000 - val_loss: 8512782336.0000\n",
      "Epoch 1381/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7332878336.0000 - val_loss: 8641726464.0000\n",
      "Epoch 1382/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7300724736.0000 - val_loss: 8170256896.0000\n",
      "Epoch 1383/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7201583104.0000 - val_loss: 8113486848.0000\n",
      "Epoch 1384/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7361462272.0000 - val_loss: 8164961792.0000\n",
      "Epoch 1385/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7287612928.0000 - val_loss: 8288586240.0000\n",
      "Epoch 1386/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7289495552.0000 - val_loss: 8196014080.0000\n",
      "Epoch 1387/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7344477696.0000 - val_loss: 8331215872.0000\n",
      "Epoch 1388/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7259487744.0000 - val_loss: 8592920576.0000\n",
      "Epoch 1389/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7380648448.0000 - val_loss: 8117997056.0000\n",
      "Epoch 1390/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7297306112.0000 - val_loss: 8741021696.0000\n",
      "Epoch 1391/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7400295424.0000 - val_loss: 8243919360.0000\n",
      "Epoch 1392/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7269690368.0000 - val_loss: 8182515200.0000\n",
      "Epoch 1393/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7350224384.0000 - val_loss: 8404928000.0000\n",
      "Epoch 1394/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7321038848.0000 - val_loss: 8116193280.0000\n",
      "Epoch 1395/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7329753600.0000 - val_loss: 8408950272.0000\n",
      "Epoch 1396/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7256762880.0000 - val_loss: 8173826048.0000\n",
      "Epoch 1397/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7432910848.0000 - val_loss: 8303878144.0000\n",
      "Epoch 1398/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7348205568.0000 - val_loss: 8490941952.0000\n",
      "Epoch 1399/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7204500480.0000 - val_loss: 8143252480.0000\n",
      "Epoch 1400/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7360130048.0000 - val_loss: 8906729472.0000\n",
      "Epoch 1401/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7247742464.0000 - val_loss: 8220021248.0000\n",
      "Epoch 1402/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7364463616.0000 - val_loss: 8187933184.0000\n",
      "Epoch 1403/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7406793216.0000 - val_loss: 8327478272.0000\n",
      "Epoch 1404/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7281836032.0000 - val_loss: 8280100352.0000\n",
      "Epoch 1405/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7250824192.0000 - val_loss: 8223653888.0000\n",
      "Epoch 1406/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7529059840.0000 - val_loss: 8393111552.0000\n",
      "Epoch 1407/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7393560576.0000 - val_loss: 8254671872.0000\n",
      "Epoch 1408/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7348046336.0000 - val_loss: 8090988032.0000\n",
      "Epoch 1409/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7312126464.0000 - val_loss: 8102888448.0000\n",
      "Epoch 1410/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7330056704.0000 - val_loss: 8145391104.0000\n",
      "Epoch 1411/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7480672256.0000 - val_loss: 8176816128.0000\n",
      "Epoch 1412/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7372833792.0000 - val_loss: 8080180224.0000\n",
      "Epoch 1413/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7486172160.0000 - val_loss: 9970632704.0000\n",
      "Epoch 1414/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7424392192.0000 - val_loss: 8270303232.0000\n",
      "Epoch 1415/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7624474112.0000 - val_loss: 8109746176.0000\n",
      "Epoch 1416/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7416986112.0000 - val_loss: 8366982144.0000\n",
      "Epoch 1417/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7247336960.0000 - val_loss: 8176876544.0000\n",
      "Epoch 1418/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7277808640.0000 - val_loss: 8326014976.0000\n",
      "Epoch 1419/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7250184704.0000 - val_loss: 8220050432.0000\n",
      "Epoch 1420/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7451613184.0000 - val_loss: 8058010112.0000\n",
      "Epoch 1421/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7266811904.0000 - val_loss: 8209256960.0000\n",
      "Epoch 1422/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7248966144.0000 - val_loss: 8313963520.0000\n",
      "Epoch 1423/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7532620288.0000 - val_loss: 8161346048.0000\n",
      "Epoch 1424/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7208907776.0000 - val_loss: 8212486144.0000\n",
      "Epoch 1425/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7334962176.0000 - val_loss: 8341927936.0000\n",
      "Epoch 1426/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7418638848.0000 - val_loss: 8246445056.0000\n",
      "Epoch 1427/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7431188480.0000 - val_loss: 8101919744.0000\n",
      "Epoch 1428/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7519360512.0000 - val_loss: 8092093952.0000\n",
      "Epoch 1429/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7303260672.0000 - val_loss: 8156606976.0000\n",
      "Epoch 1430/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7277819904.0000 - val_loss: 8119498752.0000\n",
      "Epoch 1431/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7216509440.0000 - val_loss: 8156667392.0000\n",
      "Epoch 1432/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7313981952.0000 - val_loss: 8703028224.0000\n",
      "Epoch 1433/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7192382464.0000 - val_loss: 8077505024.0000\n",
      "Epoch 1434/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7312579072.0000 - val_loss: 8135479296.0000\n",
      "Epoch 1435/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7205273600.0000 - val_loss: 8195529216.0000\n",
      "Epoch 1436/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7261544448.0000 - val_loss: 8062073856.0000\n",
      "Epoch 1437/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7369607168.0000 - val_loss: 8240017920.0000\n",
      "Epoch 1438/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7404706304.0000 - val_loss: 8214711296.0000\n",
      "Epoch 1439/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7232713728.0000 - val_loss: 8639731712.0000\n",
      "Epoch 1440/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7424900096.0000 - val_loss: 8309962752.0000\n",
      "Epoch 1441/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7376327680.0000 - val_loss: 8068038144.0000\n",
      "Epoch 1442/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7281350656.0000 - val_loss: 8156434944.0000\n",
      "Epoch 1443/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7281474560.0000 - val_loss: 8537421312.0000\n",
      "Epoch 1444/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7227280896.0000 - val_loss: 8087961600.0000\n",
      "Epoch 1445/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7222389760.0000 - val_loss: 8052787200.0000\n",
      "Epoch 1446/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7199556096.0000 - val_loss: 8222734848.0000\n",
      "Epoch 1447/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7445615616.0000 - val_loss: 8066990592.0000\n",
      "Epoch 1448/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7268271104.0000 - val_loss: 8087512064.0000\n",
      "Epoch 1449/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7237642240.0000 - val_loss: 8279030784.0000\n",
      "Epoch 1450/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7289199616.0000 - val_loss: 9474734080.0000\n",
      "Epoch 1451/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7503715840.0000 - val_loss: 8365633536.0000\n",
      "Epoch 1452/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7379088384.0000 - val_loss: 8325147648.0000\n",
      "Epoch 1453/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7273748992.0000 - val_loss: 9111702528.0000\n",
      "Epoch 1454/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7466014720.0000 - val_loss: 8421506048.0000\n",
      "Epoch 1455/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7297554432.0000 - val_loss: 8409833472.0000\n",
      "Epoch 1456/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7152508416.0000 - val_loss: 8232799232.0000\n",
      "Epoch 1457/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7412439552.0000 - val_loss: 8102951424.0000\n",
      "Epoch 1458/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7327799808.0000 - val_loss: 8366455808.0000\n",
      "Epoch 1459/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7225644032.0000 - val_loss: 8143253504.0000\n",
      "Epoch 1460/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7339481600.0000 - val_loss: 8892789760.0000\n",
      "Epoch 1461/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7244667392.0000 - val_loss: 8176908800.0000\n",
      "Epoch 1462/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7244118528.0000 - val_loss: 8143325184.0000\n",
      "Epoch 1463/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7253283840.0000 - val_loss: 8178267136.0000\n",
      "Epoch 1464/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7313256448.0000 - val_loss: 8434624000.0000\n",
      "Epoch 1465/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7411862016.0000 - val_loss: 8256503296.0000\n",
      "Epoch 1466/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7277746688.0000 - val_loss: 8094366720.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1467/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7158688768.0000 - val_loss: 8070640640.0000\n",
      "Epoch 1468/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7299337216.0000 - val_loss: 8163837440.0000\n",
      "Epoch 1469/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7345244160.0000 - val_loss: 8790993920.0000\n",
      "Epoch 1470/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7277972480.0000 - val_loss: 8131398144.0000\n",
      "Epoch 1471/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7267754496.0000 - val_loss: 8128043008.0000\n",
      "Epoch 1472/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7415925760.0000 - val_loss: 8064716800.0000\n",
      "Epoch 1473/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7426754048.0000 - val_loss: 8927295488.0000\n",
      "Epoch 1474/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7262440448.0000 - val_loss: 8040791552.0000\n",
      "Epoch 1475/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7308312064.0000 - val_loss: 8043261440.0000\n",
      "Epoch 1476/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7389991936.0000 - val_loss: 9395453952.0000\n",
      "Epoch 1477/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7576918016.0000 - val_loss: 8279958528.0000\n",
      "Epoch 1478/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7205775872.0000 - val_loss: 8144263168.0000\n",
      "Epoch 1479/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7276534272.0000 - val_loss: 8192497664.0000\n",
      "Epoch 1480/1500\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 7283437056.0000 - val_loss: 8288874496.0000\n",
      "Epoch 1481/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7336897536.0000 - val_loss: 8265681920.0000\n",
      "Epoch 1482/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7258153984.0000 - val_loss: 8488038400.0000\n",
      "Epoch 1483/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7398381056.0000 - val_loss: 8163318272.0000\n",
      "Epoch 1484/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7141633536.0000 - val_loss: 8086144512.0000\n",
      "Epoch 1485/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7246542336.0000 - val_loss: 8077895168.0000\n",
      "Epoch 1486/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7288363520.0000 - val_loss: 8202859008.0000\n",
      "Epoch 1487/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7276677632.0000 - val_loss: 8507955712.0000\n",
      "Epoch 1488/1500\n",
      "119/119 [==============================] - 2s 15ms/step - loss: 7221576192.0000 - val_loss: 8166373376.0000\n",
      "Epoch 1489/1500\n",
      "119/119 [==============================] - 2s 15ms/step - loss: 7260484096.0000 - val_loss: 8843160576.0000\n",
      "Epoch 1490/1500\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 7202332160.0000 - val_loss: 8353449984.0000\n",
      "Epoch 1491/1500\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 7488320000.0000 - val_loss: 8303734784.0000\n",
      "Epoch 1492/1500\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 7217498624.0000 - val_loss: 8030118912.0000\n",
      "Epoch 1493/1500\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7243329536.0000 - val_loss: 8359840768.0000\n",
      "Epoch 1494/1500\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 7281023488.0000 - val_loss: 8085870592.0000\n",
      "Epoch 1495/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7270811648.0000 - val_loss: 8027338240.0000\n",
      "Epoch 1496/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7196752896.0000 - val_loss: 8319448576.0000\n",
      "Epoch 1497/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7230935552.0000 - val_loss: 8122556928.0000\n",
      "Epoch 1498/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7241113600.0000 - val_loss: 8027978752.0000\n",
      "Epoch 1499/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7345438208.0000 - val_loss: 8309595648.0000\n",
      "Epoch 1500/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7235010560.0000 - val_loss: 8692998144.0000\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 19)                1558      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,098\n",
      "Trainable params: 3,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=1500)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4210f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab09b21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9ea2180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "529c8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb2bf272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825606776591423"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " r2_score(tahmin,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "106d0cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88586.73059216178"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(tahmin,y))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361df0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
